<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="pushdowndb阅读笔记, SpringBoot Java MySQL MA JavaGuy Math 算法">
    <meta name="baidu-site-verification" content="code-r7CYm21B6o" />
    <meta name="google-site-verification" content="yCy2azpds5XSuGZvis6OuA-XIGF5GuGpYRAaGfD6o48" />
    <meta name="360-site-verification" content="b7c11a830ef90fd1464ad6206bb7b6e7" />
    <meta name="description" content="1、翻译1.1、摘要Abstract—
This paper studies the effectiveness of pushing parts
of DBMS analytics queries into the Simple Stor">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>pushdowndb阅读笔记 | JavaGuy的博客</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    <style type="text/css">
        
    </style>

    <script src="/libs/jquery/jquery-2.2.0.min.js"></script>
    <script src="https://sdk.jinrishici.com/v2/browser/jinrishici.js" charset="utf-8"></script>
    <script>
        var _hmt = _hmt || [];
        (function () {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?ce84511d3df71640a9378a69f6293044";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>

    
        <script>
            (function(){
                var bp = document.createElement('script');
                var curProtocol = window.location.protocol.split(':')[0];
                if (curProtocol === 'https') {
                    bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
                }
                else {
                    bp.src = 'http://push.zhanzhang.baidu.com/push.js';
                }
                var s = document.getElementsByTagName("script")[0];
                s.parentNode.insertBefore(bp, s);
            })();
        </script>
    

    <script>
        (function(){
        var src = "https://jspassport.ssl.qhimg.com/11.0.1.js?d182b3f28525f2db83acfaaf6e696dba";
        document.write('<script src="' + src + '" id="sozz"><\/script>');
        })();
    </script>

<meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="JavaGuy的博客" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>

<body>

    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">JavaGuy的博客</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fa fa-navicon"></i></a>
<ul class="right">
    
    <li class="hide-on-med-and-down">
        <a href="/" class="waves-effect waves-light">
            
            <i class="fa fa-home"></i>
            
            <span>首页</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/tags" class="waves-effect waves-light">
            
            <i class="fa fa-tags"></i>
            
            <span>标签</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/categories" class="waves-effect waves-light">
            
            <i class="fa fa-bookmark"></i>
            
            <span>分类</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/archives" class="waves-effect waves-light">
            
            <i class="fa fa-archive"></i>
            
            <span>归档</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/about" class="waves-effect waves-light">
            
            <i class="fa fa-user-circle-o"></i>
            
            <span>关于</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/friends" class="waves-effect waves-light">
            
            <i class="fa fa-address-book"></i>
            
            <span>友情链接</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/contact" class="waves-effect waves-light">
            
            <i class="fa fa-comments"></i>
            
            <span>留言板</span>
        </a>
    </li>
    
    <li>
        <a href="#searchModal" class="modal-trigger waves-effect waves-light">
            <i id="searchIcon" class="fa fa-search" title="搜索"></i>
        </a>
    </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">JavaGuy的博客</div>
        <div class="logo-desc">
            
            华中科技大学 | 计算机科学与技术 | 分布式云数据库内核
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li>
            <a href="/" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-home"></i>
                
                首页
            </a>
        </li>
        
        <li>
            <a href="/tags" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-tags"></i>
                
                标签
            </a>
        </li>
        
        <li>
            <a href="/categories" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-bookmark"></i>
                
                分类
            </a>
        </li>
        
        <li>
            <a href="/archives" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-archive"></i>
                
                归档
            </a>
        </li>
        
        <li>
            <a href="/about" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-user-circle-o"></i>
                
                关于
            </a>
        </li>
        
        <li>
            <a href="/friends" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-address-book"></i>
                
                友情链接
            </a>
        </li>
        
        <li>
            <a href="/contact" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-comments"></i>
                
                留言板
            </a>
        </li>
        
        
    </ul>
</div>

        </div>

        
    </nav>

</header>

    
<script src="/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '91a6f824b85ba9ed6e7cf599364e2f8bc897a465357160c6425c8eacd8883377';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/27.jpg')">
    <div class="container">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <div class="description center-align post-title">
                        pushdowndb阅读笔记
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>



<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 20px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        <span class="chip bg-color">无标签</span>
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                </div>
            </div>

            <div class="post-info">
                <div class="post-date info-break-policy">
                    <i class="fa fa-calendar-minus-o fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2021-05-11
                </div>

                <div class="post-author info-break-policy">
                    <i class="fa fa-user-o fa-fw"></i>作者:&nbsp;&nbsp;
                    
                    JavaGuy
                    
                </div>

                
                
                <div class="info-break-policy">
                    <i class="fa fa-file-word-o fa-fw"></i>文章字数:&nbsp;&nbsp;
                    17.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="fa fa-clock-o fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    81 分
                </div>
                
                

                
                <div id="busuanzi_container_page_pv" class="info-break-policy">
                    <i class="fa fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                    <span id="busuanzi_value_page_pv"></span>
                </div>
                
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="1、翻译"><a href="#1、翻译" class="headerlink" title="1、翻译"></a>1、翻译</h1><h2 id="1-1、摘要"><a href="#1-1、摘要" class="headerlink" title="1.1、摘要"></a>1.1、摘要</h2><pre><code>Abstract—
This paper studies the effectiveness of pushing parts
of DBMS analytics queries into the Simple Storage Service
(S3) engine of Amazon Web Services (AWS), using a recently
released capability called S3 Select. We show that some DBMS
primitives (filter, projection, aggregation) can always be cost effectively moved into S3. Other more complex operations (join,
top-K, group-by) require reimplementation to take advantage of
S3 Select and are often candidates for pushdown. We demonstrate
these capabilities through experimentation using a new DBMS
that we developed, PushdownDB. Experimentation with a collection of queries including TPC-H queries shows that PushdownDB
is on average 30% cheaper and 6.7× faster than a baseline that
does not use S3 Select
</code></pre>
<pre><code>摘要
本文研究了下推一部分DBMS分析查询到简单存储服务中的有效性。
最近使用的Amazon Web Services（AWS）的（S3）引擎发布了称为S3 Select的功能。 我们展示了一些DBMS原语（过滤器，投影，聚合）始终可以经济高效地移入S3。 其他更复杂的操作（连接，top-K，分组）需要重新实现以利用S3选择，这些通常是下推的候选对象。 我们展示通过使用新的DBMS进行实验来获得这些功能，即我们开发的PushdownDB。 对包括TPC-H查询的查询集合进行的实验表明，PushdownDB比不使用S3 Select的基线平均便宜30％，快6.7倍。
</code></pre>
<h2 id="1-2、概要"><a href="#1-2、概要" class="headerlink" title="1.2、概要"></a>1.2、概要</h2><pre><code>Clouds offer cheaper and more flexible computing than
“on-prem”. Not only can one add resources on the fly, the
large cloud vendors have major economies of scale relative to
“on-prem” deployment. Modern clouds employ an architecture
where the computation and storage are disaggregated — the
two components are independently managed and connected
using a network. Such an architecture allows for independent
scaling of computation and storage, which simplifies the
management of storage and reduces its cost. A number of data
warehousing systems have been built to analyze data on disaggregated cloud storage, including Presto [1], Snowflake [2],
Redshift Spectrum [3], among others.
</code></pre>
<pre><code>云比“本地”提供更便宜更灵活的计算。 不仅可以即时添加资源，相比于“本地”部署，大型云供应商有大规模经济体量。 现代云采用计算与存储分离架构-
两个组件是独立管理的，通过网络连接。 这样的架构允许独立计算和存储的扩展，简化了存储层的管理并且降低了成本。 大量数据仓库系统被建立来分析分布式云存储上的数据，包括Presto [1]，Snowflake [2]，Redshift Spectrum [3]等。
</code></pre>
<pre><code>In a disaggregated architecture, the network that connects
the computation and storage layers can be a major performance
bottleneck. The internal bandwidth of the storage devices
within a storage server is much higher than the external
network bandwidth commonly offered by cloud storage. As a
result, a database running on a disaggregated architecture may
underperform a database on a conventional shared-nothing
architecture, where the storage devices are attached to the
compute servers themselves [4].
</code></pre>
<pre><code>在计算与存储分离的架构中，连接计算层和存储层的网络可能是主要性能瓶颈。 存储服务器中的存储设备的内部带宽比外部存储服务器高得多。 因此，在分离架构上运行的数据库可能会比传统的无共享架构的数据库表现不佳。
</code></pre>
<pre><code>Two intuitive solutions exist to mitigate the network bottleneck: caching and computation pushdown. With caching,
a compute server loads data from the remote storage once,
caches it in main memory or local storage, and reuses it across
multiple queries, thereby amortizing the network transfer cost.
Caching has been implemented in Snowflake [2] and the
Redshift [5] layer of Redshift Spectrum [3]. With computation
pushdown, a database management system (DBMS) pushes its functionality as close to storage as possible. A pioneering paper by Hagmann [6] studied the division of SQL code between
the storage layer and the application layer and concluded that
performance was optimized if all code was moved into the
storage layer. Moreover, one of the design tenets of the BrittonLee IDM 500 [7], the Oracle Exadata server [8], and the IBM
Netezza machine [9] was to push computation into specialized
processors that are closer to storage
</code></pre>
<pre><code>有两种直观的解决方案可以缓解网络瓶颈：缓存和计算下推。 有了缓存，计算服务器一次从远程存储加载数据，将其缓存在主内存或本地存储中，并在多次查询中重复使用
，从而分摊网络传输成本。缓存已在Snowflake [2]和Redshift Spectrum [3]的Redshift [5]层中实现。计算下推时，数据库管理系统（DBMS）会将其功能推向尽可能接近存储的地方。 Hagmann [6]的开创性论文研究了存储层和应用层SQL代码之间的划分，得出的结论是：如果所有代码都移入了存储层，性能会得到提升。 此外，Britton Lee IDM 500 [7]，Oracle Exadata服务器[8]和IBM Netezza机器[9]的设计原则之一是：将计算下推到距离存储更近的特定处理器。
</code></pre>
<pre><code>Recently, Amazon Web Services (AWS) introduced a feature called “S3 Select”, through which limited computation
can be pushed onto their shared cloud storage service called
S3 [10]. This provides an opportunity to revisit the question of
how to divide query processing tasks between S3 storage nodes
and normal computation nodes. The question is nontrivial as
the limited computational interface of S3 Select allows only
certain simple query operators to be pushed into the storage
layer, namely selections, projections, and simple aggregations.
Other operators require new implementations to take advantage of S3 Select. Moreover, S3 Select pricing can be more
expensive than computing on normal EC2 nodes.
</code></pre>
<pre><code>最近，Amazon Web Services（AWS）引入了一项称为“ S3 Select”的功能，通过该功能有限的计算能被推送到他们的共享云存储服务上，该服务称为
S3 [10]。 这提供了一个机会来重新考虑以下问题：如何在S3存储节点和计算节点之间划分查询处理任务。 这个问题是重要的，因为S3 Select的有限计算接口仅允许
某些简单的查询运算将被下推到存储层，即选择，投影和简单聚合。其他运算需要重新实现以利用S3 Select。 而且，S3 Select可能比在普通EC2节点上进行计算要更昂贵。
</code></pre>
<pre><code>In this paper, we set our goal to understand the performance
of computation pushdown when running queries in a cloud
setting with disaggregated storage. Specifically, we consider
filter (with and without indexing), join, group-by, and top-K as
candidates. We implement these operators to take advantage of
computation pushdown through S3 Select and study their cost
and performance. We show dramatic performance improvement and cost reduction, even with the relatively high cost
of S3 Select. In addition, we analyze queries from the TPCH benchmark and show similar benefits of performance and
cost. We also point out the limitations of the current S3 Select
service and provide several suggestions based on the lessons
we learned from this project. To the best of our knowledge,
this is the first extensive study of pushdown computing for
database operators in a disaggregated architecture.
</code></pre>
<pre><code>在本文中，我们的目标是理解在使用计算存储分离的云设置中运行查询时计算下推的性能。 具体来说，我们考虑过滤器（带有和不带有索引），连接，分组和top-K。 我们通过S3实现这些操作以利用计算下推并研究其成本和性能。 即使S3 select成本相对较高，我们也能看到显著的性能提升和成本的下降。 此外，我们分析了来自TPCH基准的查询，表现出了类似的性能和成本效益。 我们还指出了当前S3 Select的局限性，并根据我们从这个项目中学到的东西提供一些建议。 据我们所知，这是在计算与存储分离架构下对数据库操作计算下推的首次广泛研究。
</code></pre>
<pre><code>For the rest of this paper, Section II describes the cloud
environment of our evaluation. Section III describes the PushdownDB database we implemented. Then Sections IV–VII describe how filter, join, group-by, and top-K can leverage S3 Select, and evaluates the performance using micro benchmarks.
Section VIII shows evaluation on the TPC-H benchmark suite.
Section IX evaluates the Parquet data format. Section X discusses ways to improve the current S3 Select interface.
Finally, Section XI describes related work and Section XII
concludes the paper
</code></pre>
<pre><code>在本文的其余部分，第二节介绍了我们评估的云环境。 第三节介绍了我们实现的PushdownDB数据库。 然后，第IV–VII节描述了过滤，连接，分组和top-K如何利用S3选择，并使用微基准测试评估性能。第VIII节展示了对TPC-H基准套件的评估。第IX节评估了Parquet数据格式。 第X节讨论了改进当前S3 Select接口的方法。
最后，第XI部分描述了相关工作，而第XII部分总结本文。
</code></pre>
<h2 id="1-3、云上的数据管理"><a href="#1-3、云上的数据管理" class="headerlink" title="1.3、云上的数据管理"></a>1.3、云上的数据管理</h2><pre><code>Cloud providers such as AWS offer a wide variety of
computing services, and renting nodes is a basic one. In
AWS, this service is called Elastic Compute Cloud (EC2).
EC2 computing nodes (called instances) come in different
configurations and can have locally-attached storage
</code></pre>
<pre><code>AWS等云提供商提供了多种计算服务，其中租用节点是基本的服务。 在AWS，此服务称为弹性计算云（EC2）。EC2计算节点（称为实例）配置不同，并且可以具有本地连接的存储。
</code></pre>
<pre><code>In the context of a DBMS, EC2 instances are used to execute
SQL queries. AWS offers Simple Storage Service (S3) [11],
a highly available object store. S3 provides virtually infinite
storage capacity for regular users with relatively low cost,
and is supported by most popular cloud databases, including
Presto [1], Hive [12], Spark SQL [13], Redshift Spectrum [3],
and Snowflake [2]. The storage nodes in S3 are separate from
compute nodes. Hence, a DBMS uses S3 as a storage system
and transfers needed data over a network for query processing.
</code></pre>
<pre><code>在DBMS的环境下，使用EC2实例执行SQL查询。 AWS提供了简单存储服务（S3）[11]，是一个高度可用的对象存储。 S3给普通用户提供几乎无限的的存储容量，成本相对较低，并受到大多数流行的云数据库的支持，包括Presto [1]，Hive [12]，Spark SQL [13]，Redshift Spectrum [3]，和Snowflake[2]。 S3中的存储节点与
计算节点是分离的。 因此，DBMS使用S3作为存储系统，并通过网络传输所需的数据以进行查询处理。
</code></pre>
<pre><code>S3 is a popular storage choice for cloud databases, since S3
storage is much cheaper than locally-attached and/or block-based alternatives, e.g., Elastic Block Store (EBS). In addition,
S3 data can be shared across multiple computing instances.
</code></pre>
<pre><code>S3是云数据库的流行存储选择，因为S3存储比本地连接存储和/或基于块的替代方案（例如，弹性块存储（EBS））便宜得多。 此外，S3数据可以在多个计算实例之间共享。
</code></pre>
<h3 id="1-3-1、S3-Select"><a href="#1-3-1、S3-Select" class="headerlink" title="1.3.1、S3 Select"></a>1.3.1、S3 Select</h3><pre><code>To reduce network traffic and the associated processing
on compute nodes, AWS released a new service called S3
Select [10] in 2018 to push limited computation to the storage
nodes. Normal S3 supports put/get operators that write/read
a whole object or part of it (based on byte offsets). S3
Select adds support for a limited set of SQL queries. At the
current time, S3 Select supports only selection, projection,
and aggregation without group-by for tables using the CSV
or Parquet [14] format.
</code></pre>
<pre><code>为了减少在计算节点上的网络流量和相关处理，在2018年AWS发布了一项名为S3 Select的新服务，该服务将有限的计算下推到存储节点。 普通的S3支持put/get的操作来write/read整个对象或对象的一部分（基于字节偏移量）。 S3 Select添加了对一组有限的SQL查询的支持。 目前，S3 Select仅支持选择，投影，聚合，在使用CSV或者Parquet格式的表时，不支持group by。
</code></pre>
<pre><code>We show examples of the SQL queries supported by S3
Select in the subsequent sections. S3 Select implements these
operators by scanning the rows in the table and returning
qualifying rows to the compute node. More sophisticated
operations such as join, group by, and top-K are not supported
by S3 Select and need to be executed at a compute node.
Redesigning these more complex query operators to use S3
Select is challenging. For example, supporting a join operator
will require data shuffling among storage nodes. In this paper,
we study how these advanced operators can be broken down
into simpler ones to leverage S3 Select. We propose and
evaluate several implementations of these more advanced
operators and show that they can often be made faster and
cheaper than loading all data into EC2 compute nodes.
</code></pre>
<pre><code>在随后的部分中，我们展示了S3 Select支持的SQL查询的示例。 S3 Select实现了这些操作，通过扫描表中的行并返回符合条件的行给计算节点。 更复杂的操作如join，group by和top-K不被S3 Select支持，需要在计算节点上执行。重新设计这些更复杂的查询操作以使用S3 Select是具有挑战性的。 例如，支持join操作将需要在存储节点之间进行数据转移。 在本文中，我们研究了如何分解这些高级操作为更简单的操作，以利用S3 Select。 我们提出并评估这些更高级操作的几种实现，并表明它们通常比将所有数据加载到EC2计算节点更快，更便宜。
</code></pre>
<h3 id="1-3-2、计算查询代价"><a href="#1-3-2、计算查询代价" class="headerlink" title="1.3.2、计算查询代价"></a>1.3.2、计算查询代价</h3><pre><code>The dollar cost of queries is a crucial factor, since it is one of
the main reasons to migrate an application from “on-prem” to
the cloud. For the same AWS service, cost varies based on the
region where the users data and computation are located. We
limit our cost calculation to US East (N. Virginia) pricing. In
this section, we discuss the costs associated with the services.
we use in our experiments: storage, data access, data transfer,
network requests, and computation on EC2 instances.
</code></pre>
<pre><code>查询的美元成本是一个关键因素，因为它是将应用程序从“本地”迁移到云端的主要原因之一。 对于相同的AWS服务，费用会因用户数据和计算所在的区域而异。 我们
将我们的费用计算限制为美国东部（弗吉尼亚北部）的定价。 在本节中，我们讨论与服务相关的成本。
我们在实验中使用的是：存储，数据访问，数据传输，网络请求以及EC2实例上的计算。
</code></pre>
<h4 id="1-3-2-1、Storage-cost-（存储成本）"><a href="#1-3-2-1、Storage-cost-（存储成本）" class="headerlink" title="1.3.2.1、Storage cost.（存储成本）"></a>1.3.2.1、Storage cost.（存储成本）</h4><pre><code>S3 storage cost is charged monthly based on
the amount of space used. For example, S3 standard storage
costs about $0.022/GB/month. Although other AWS storage
services may offer better IO performance, they are also more
expensive than S3. Since the storage cost only depends on
data size and not on frequency of access, we exclude it when
calculating query cost in this paper.
</code></pre>
<pre><code>S3存储费用基于使用的空间量按月收取。 例如，S3标准存储费用约为$ 0.022 / GB /月。 虽然其他AWS存储服务可能会提供更好的IO性能，但是他们也比S3贵。 由于存储成本仅取决于数据大小而不是访问频率，所以本文我们在计算查询成本时将其排除了。
</code></pre>
<h4 id="1-3-2-2、Data-transfer-cost-（数据传输成本）"><a href="#1-3-2-2、Data-transfer-cost-（数据传输成本）" class="headerlink" title="1.3.2.2、Data transfer cost.（数据传输成本）"></a>1.3.2.2、Data transfer cost.（数据传输成本）</h4><pre><code>AWS S3 users are charged for only the
outgoing traffic and the price is based on the destination of
the data. When S3 Select is not used, this price ranges from
free (transferring data within the same region) to $0.09/GB
(transferring data out of AWS). Servers in our experiments
are within the same region as the S3 data. Therefore, we do
not pay any data transfer cost.
</code></pre>
<pre><code>AWS S3用户仅需支付传出流量，并且价格基于数据目的地。 当不使用S3 Select时，此价格范围为免费（在同一区域内传输数据）至$ 0.09 / GB
（将数据从AWS传输出去）。 我们实验中的服务器与S3数据在同一区域内。 因此，我们不支付任何数据传输费用。
</code></pre>
<h4 id="1-3-2-3、S3-Select-Cost-（S3-Select-成本）"><a href="#1-3-2-3、S3-Select-Cost-（S3-Select-成本）" class="headerlink" title="1.3.2.3、S3 Select Cost.（S3 Select 成本）"></a>1.3.2.3、S3 Select Cost.（S3 Select 成本）</h4><pre><code>S3 Select introduces a new cost component
that is based on the amount of data scanned ($0.002/GB)
in processing an S3 Select query and the amount of data
returned ($0.0007/GB). The cost for data return depends on the
selectivity of the query. Data scan and transfer cost is typically
a major component in overall query cost when S3 Select is in
use.
</code></pre>
<pre><code>S3 Select在处理S3 Select查询和返回数据量（$ 0.0007 / GB）时引入了新的成本构成：根据扫描的数据量进行计算（$ 0.002 / GB）。 数据返回的费用取决于
查询的选择性。 当S3被使用时，数据扫描和传输成本通常是整体查询成本的主要组成部分。
</code></pre>
<h4 id="1-3-2-4、Network-request-cost-（网络请求成本）"><a href="#1-3-2-4、Network-request-cost-（网络请求成本）" class="headerlink" title="1.3.2.4、Network request cost.（网络请求成本）"></a>1.3.2.4、Network request cost.（网络请求成本）</h4><pre><code>Issuing HTTP requests to Amazon
S3 is charged based on the request type and the number of
requests. We consider only the cost of HTTP GET requests
($0.0004 per 1,000 requests) as this is the only request type
we use. This cost is paid for both S3 Select requests and
conventional table read requests.
</code></pre>
<pre><code>向亚马逊S3发出HTTP请求是根据请求类型和数量收费的。我们只考虑HTTP GET请求的费用（每1,000个请求$ 0.0004），因为这是我们使用的唯一请求类型。 这笔费用是针对S3 Select请求和常规的表读取请求。
</code></pre>
<h4 id="1-3-2-5、Computation-cost-（计算成本）"><a href="#1-3-2-5、Computation-cost-（计算成本）" class="headerlink" title="1.3.2.5、Computation cost.（计算成本）"></a>1.3.2.5、Computation cost.（计算成本）</h4><pre><code>We used EC2 memory-optimized instances for our experiments. The query execution time is
measured in seconds and used to calculate the computation
cost based on the hourly price of the host EC2 instance (e.g.,
r4.8xlarge instances costs $2.128 per hour). The computation
cost is another significant component of the overall query cost.
</code></pre>
<pre><code>我们在实验中使用了EC2内存优化的实例。 查询执行时间以秒为单位进行测量，并且计算费用基于主机EC2实例的每小时价格（例如，r4.8xlarge实例的费用为每小时2.128美元）。 计算费用是整个查询费用的另一个重要组成部分。
</code></pre>
<h2 id="1-4、数据库测试：PushdownDB"><a href="#1-4、数据库测试：PushdownDB" class="headerlink" title="1.4、数据库测试：PushdownDB"></a>1.4、数据库测试：PushdownDB</h2><pre><code>In order to explore how S3 Select can be leveraged to improve query performance and/or reduce cost, we implemented
a bare-bone row-based DBMS testbed, called PushdownDB.
We concluded that modifying a commercial multi-node DBMS
(e.g., Presto) would be a prohibitive amount of work. Instead,
we implemented PushdownDB which has a minimal optimizer
and an executor that enables the experiments in this paper
</code></pre>
<pre><code>为了探索如何利用S3 Select来改善查询性能或降低成本，我们实现了一个基于裸行的DBMS测试平台，称为PushdownDB。
我们得出的结论是，修改商业多节点DBMS（例如Presto）将是一项令人望而却步的工作。相反，我们实现了具有最小优化器的PushdownDB以及执行本文中的实验的执行器。
</code></pre>
<pre><code>We made a reasonable effort to optimize PushdownDB’s
performance. While we could not match the performance of
the more mature Presto system on all queries, we obtained
competitive performance, as shown in Section VIII. The source
code of PushdownDB is available on github at https://github.
com/yxymit/s3filter.git, and is implemented in a mixture of
C++ and Python.
</code></pre>
<pre><code>我们做出了合理的努力来优化PushdownDB的性能。 虽然我们无法达到更成熟的Presto系统在所有查询上的性能表现
但是我们还是获得了不错的竞争力表现，如第八节所示。PushdownDB的源码可在github（https://github.com/yxymit/s3filter.git）上获得，并且混合使用
C++和Python。
</code></pre>
<pre><code>PushdownDB represent the query plan as a directed acyclic
graph and executes queries in either serial or parallel mode. In
the serial mode, a single CPU executes one operator at a time.
In the parallel mode, each operator executes in parallel using multiple Python processes and passes batches of tuples from
producer to consumer using a queue. Most operators achieve
better performance in the parallel mode, but some operators
can benefit from serial mode. A projection followed by a filter,
for example, can demonstrate better performance when run
in the same process, because this avoids inter-process data
transfers. Most queries in this paper are executed in a mixture
of the two modes.
</code></pre>
<pre><code>PushdownDB将查询计划表示为有向无环图，并以串行或并行模式执行查询。在串行模式下，单个CPU一次执行一个操作。在并行模式下，每个操作都使用多个Python进程并行执行，并从生产者到消费者批量传递元组使用队列。 大多数操作在并行模式下性能更好，但是某些操作在串行模式下更好。 例如，带过滤器的投影运行在同一进程中可以展示出更好的性能，因为这避免了过程间数据传输。 本文中的大多数查询是两种模式混合执行的。
</code></pre>
<pre><code>A few performance optimizations have been built into PushdownDB. For example, PushdownDB does not use SSL as we
expect analytics workloads would typically be run in a secure
environment. Also, PushdownDB uses the Pandas library [15]
to represent collections of tuples as data frames, generating
a significant performance advantage over implementing tuple
processing in plain Python.
</code></pre>
<pre><code>PushdownDB中已内置了一些性能优化。 例如，PushdownDB不使用SSL，因为我们期望分析工作负载通常将运行在安全的环境中。 另外，PushdownDB使用Pandas库[15]将元组的集合表示为数据帧，用纯Python实现元组处理产生了显著的性能优势。
</code></pre>
<pre><code>Experimental Setup. Experiments in this paper are performed
on an r4.8xlarge EC2 instance, which contains 32 physical
cores, 244 GB of main memory, and a 10 GigE network. The
machine runs Ubuntu 16.04.5 LTS. PushdownDB is executed
using Python version 2.7.12.
</code></pre>
<pre><code>实验环境配置。
本文进行的实验在r4.8xlarge EC2实例上，其中包含32个物理核心，244 GB主内存和10 GigE网络。机器运行在Ubuntu 16.04.5 LTS上。 PushdownDB使用Python版本2.7.12执行。
</code></pre>
<pre><code>Unless otherwise stated, all experiments use the same 10 GB
TPC-H dataset in CSV format. We will also report Parquet experiments in Section IX. To facilitate parallel processing, each
table is partitioned into multiple objects in S3. The techniques
discussed in this paper do not make any assumptions about
how the data is partitioned. During execution, PushdownDB
spawns multiple processes to load data partitions in parallel.
</code></pre>
<pre><code>除非另有说明，否则所有实验均使用相同的10 GB CSV格式的TPC-H数据集。 我们还将在第IX节中报告Parquet格式的实验。 为了便于并行处理，每个表在S3中被划分为多个对象。 本文讨论的技术对于数据如何分区不做任何假设。 在执行期间，PushdownDB产生多个进程以并行加载数据分区。
</code></pre>
<h2 id="1-5、过滤器"><a href="#1-5、过滤器" class="headerlink" title="1.5、过滤器"></a>1.5、过滤器</h2><pre><code>This section discusses how PushdownDB accelerates filter
operators using S3 Select. Given that it is straightforward
to pushdown a where clause to S3, we focus on the more
interesting problem of supporting indexing using S3 Select.
</code></pre>
<pre><code>本节讨论PushdownDB如何使用S3 Select加速过滤器操作。 鉴于它直接将where子句下推到S3，我们将重点放在使用S3 Select支持索引的有趣问题。
</code></pre>
<h3 id="1-5-1、Indexing-with-S3-Select"><a href="#1-5-1、Indexing-with-S3-Select" class="headerlink" title="1.5.1、Indexing with S3 Select"></a>1.5.1、Indexing with S3 Select</h3><pre><code>Both hash indexes and tree-based indexes are widely used in
database systems. Neither implementation, however, is a good
fit for a cloud storage environment because a single index
lookup requires multiple accesses to the index. This causes
multiple S3 requests that incur long network delays. To avoid
this issue, we designed an index table that is amenable to the
filtering available in S3 Select.
</code></pre>
<pre><code>哈希索引和基于树的索引都广泛用于数据库系统。 但是，两种实现对于云存储环境都不是一个好的选择，因为单个索引查找需要对索引的多次访问。 这导致多个S3请求会产生较长的网络延迟。为了避免这个问题，我们设计了一个索引表，可以接受S3 Select中可用的过滤。
</code></pre>
<pre><code>An index table contains the values of the columns to be
indexed, as well as the byte offsets of indexed records in that
table. Specifically, an index table has the following schema
(assuming the index is built on a single column).
</code></pre>
<pre><code>索引表包含要建立索引列的值，以及其中索引记录的字节偏移量。 具体来说，索引表具有以下结构（假设索引建立在单个列上）。
</code></pre>
<blockquote>
<p>|value|first_byte_offset|last_byte_offset|</p>
</blockquote>
<pre><code>Accessing a table through an index comprises two phases.
In phase 1, the predicate on the indexed columns is sent to the
index table using an S3 Select request. Then the byte offsets
of selected rows are returned to the compute server. In phase
2, the byte offsets are used to directly load the corresponding
rows from the data table, by sending an HTTP request for
each individual row. Note that accesses in the second phase
do not use S3 Select and therefore do not incur the associated
extra cost.
</code></pre>
<pre><code>通过索引访问表包括两个阶段。在阶段1中，索引列上的谓词使用S3 Select请求被发送到索引表。 然后选定行的字节偏移量返回给计算服务器。 在阶段2，通过对每一行发送HTTP请求，字节偏移量直接用于从数据表中装载相应行。 请注意，第二阶段的访问不会使用S3 Select，因此不会产生额外开销。
</code></pre>
<p><img src="https://zhangqu-oss.oss-cn-zhangjiakou.aliyuncs.com/img/image-20210512113333850.png" alt="image-20210512113333850"></p>
<pre><code>图1：过滤器算法—三种过滤策略的性能和成本（随着过滤器选择性的变化）
</code></pre>
<h3 id="1-5-2、Performance-Evaluation"><a href="#1-5-2、Performance-Evaluation" class="headerlink" title="1.5.2、Performance Evaluation"></a>1.5.2、Performance Evaluation</h3><pre><code>Figure 1 shows the runtime and cost of different filtering
algorithms as the filter selectivity increases from 10−7
to 10−2.
Server-side filter loads the entire table from S3 and performs
filtering on the compute node. S3-side filter sends the filtering
predicate to S3 in an S3 Select request. S3-side indexing uses
the index table implementation.
</code></pre>
<pre><code>图1显示了不同过滤算法的运行时间和成本（随着过滤器选择性从10−7增加到10−2）
服务器端过滤器从S3加载整个表并在计算节点上进行过滤。 S3端过滤器在一次S3 Select请求中发送过滤谓词给S3。 S3端索引使用索引表的实现。
</code></pre>
<pre><code>The performance improvement (Figure 1a) from server-side
filter to S3-side filter is a dramatic 10× and remains stable
as selectivity changes in the specified range. S3-side indexing
has similar performance as S3-side filter when the filter is
highly selective, but the performance of indexing degrades as
the the filter selects more than 10−4 of the rows. In this case,
more rows are returned and most of the execution time is
spent requesting and receiving individual byte ranges from the
data table. Although these requests are sent in parallel, they
incur excessive CPU computation that become a performance
bottleneck.
</code></pre>
<pre><code>服务器端的过滤器到S3端过滤器的性能改进（图1a）是惊人的10倍，并且保持稳定增长（随着选择性在指定范围内变化）。 当过滤器为高选择性时，S3端索引和S3端过滤器有相似的性能表现，但当过滤器选择的行数超过10−4时，索引的性能会降低。 在这种情况下，更多行被返回了，大部分执行时间被花在请求和接收数据表范围内的单个字节。 尽管这些请求是并行发送的，但它们导致过多的CPU计算，这是一个性能瓶颈。
</code></pre>
<pre><code>The cost (Figure 1b) of each run is broken down into four
components: compute cost, S3 request cost, S3 data scan cost,
and data transfer cost. Each component is denoted using a
different type of hash marks. Overall, S3-side filter is 24%
more expensive than server-side filter. Most of the cost of S3-
side filter is due to S3 data scanning and loading, while most
of the cost of server-side filter is due to computation. S3-
side indexing is cheaper than server-side filter by 2.7× when
the filter is very selective, because the index table redues the
amount of data being scanned and transferred. As the filter
passes more data, however, the cost of indexing grows rapidly
due to increasing HTTP requests.
</code></pre>
<pre><code>每次运行的成本（图1b）分为四部分：计算成本，S3请求成本，S3数据扫描成本，和数据传输成本。 每个部分都使用一个不同类型的哈希标记。 总体而言，S3侧过滤器为比服务器端过滤器贵24％。 S3端过滤器的大部分费用归因于S3数据的扫描和加载，而大多数服务器端过滤器的成本归因于计算。 当过滤器的选择性很强时，S3端索引比服务器端过滤器便宜2.7倍，因为索引表会减少扫描和传输的数据量。但是随着过滤器传递更多数据，索引成本迅速增加，这是因为增加了HTTP请求。
</code></pre>
<pre><code>In conclusion, S3-side indexing is the best approach with highly selective queries, whereas S3-side filter achieves a good
balance between performance and cost for queries with any
selectivity.
</code></pre>
<pre><code>总而言之，S3端索引是具有高度选择性查询的最佳方法，而S3端过滤器则可以很好地实现在任何选择性情况下查询的性能和成本之间的平衡。
</code></pre>
<h2 id="1-6、连接"><a href="#1-6、连接" class="headerlink" title="1.6、连接"></a>1.6、连接</h2><pre><code>S3 Select does not support pushing a join operator in its
entirety into S3. This section shows how PushdownDB breaks
down a join to partially leverage S3 Select
</code></pre>
<pre><code>S3 Select在整个S3里不支持下推连接操作。 本节说明PushdownDB如何分解连接以部分利用S3 Select
</code></pre>
<pre><code>It is inherently difficult to take advantage of pushdown
processing for joins. The two tables to be joined are typically
partitioned across multiple S3 objects so that data can be
loaded in parallel. If the two tables are not partitioned on the
join key, implementing a join operator requires shuffling data
among different partitions, which is challenging to support
at the storage layer. PushdownDB supports joining tables not
partitioned on the join key, as we describe next.
</code></pre>
<pre><code>本质上是很难下推连接的。 通常要连接的两个表跨多个S3对象进行分区，以便可以将数据并行加载。 如果两个表连接键不在同一个分区，那么实现连接操作需要在不同的分区之间移动数据，这在存储层很难支持。 PushdownDB支持待联接的表在联接键上处于不同分区，如下所述。
</code></pre>
<pre><code>We limit our discussion to hash joins implemented using
two phases: the build phase loads the smaller table in parallel
and sends each tuple to the appropriate partition to build a
hash table; the probe phase loads the bigger table in parallel
and sends the tuples to the correct partition to join matching
tuples by probing the hash table.
</code></pre>
<pre><code>我们的讨论仅限于使用以下两阶段方法实现的哈希联接：
构建阶段并行加载较小的表并将每个元组发送到适当的分区以构建一个哈希表; 
探针阶段并行加载较大的表并将元组发送到正确的分区通过探查哈希表来连接匹配的元组。
</code></pre>
<h3 id="1-6-1、连接算法"><a href="#1-6-1、连接算法" class="headerlink" title="1.6.1、连接算法"></a>1.6.1、连接算法</h3><pre><code>PushdownDB supports three join algorithms: Baseline Join,
Filtered Join, and Bloom Join. These algorithms leverage S3
Select in different ways.
</code></pre>
<pre><code>PushdownDB支持三种联接算法：基准联接，过滤联接和Bloom联接。 这些算法以不同的方式利用S3 Select。
</code></pre>
<pre><code>In baseline join, the server loads both tables from S3 and
executes the hash join locally, without using S3 Select. Filtered
join pushes down selection and projection using S3 Select, and
executes the rest of the query in the same way as baseline join.
We will not discuss these two algorithms in detail due to their
limited use of S3 Select.
</code></pre>
<pre><code>在基准连接中，服务器从S3中加载这两个表并且在不使用S3 Select的情况下在本地执行哈希联接。 过滤连接使用S3 Select下推选择和投影，并且与基准连接相同的方式执行其余查询。由于这两种算法对S3 Select使用不多，我们将不对其进行详细讨论。
</code></pre>
<pre><code>In this section, we focus our discussion on Bloom join: after
the build phase, a Bloom filter is constructed based on the join
keys in the first table; the Bloom filter is then sent as an S3
Select request to load a filtered version of the second table.
In other words, rows that do not pass the Bloom filter are not
returned.
</code></pre>
<pre><code>在本节中，我们将讨论重点放在Bloom连接上：构建阶段之后，将基于第一个表中的连接键构造一个Bloom过滤器； 然后作为加载第二个表的过滤版本的S3 Select请求将Bloom过滤器发送。换句话说，没有通过布隆过滤器的行不会被返回。
</code></pre>
<h4 id="1-6-1-1、布隆过滤器"><a href="#1-6-1-1、布隆过滤器" class="headerlink" title="1.6.1.1、布隆过滤器"></a>1.6.1.1、布隆过滤器</h4><pre><code>1) Bloom Filter: A Bloom filter [16] is a probabilistic data
structure that determines whether an element exists in a set
or not. A Bloom filter has no false negatives but may have
false positives. If a Bloom filter returns false, the element
is definitely not in the set; if a Bloom filter returns true,
the element may be in the set. Compared to other data
structures achieving the same functionality, a Bloom filter has
the advantage of high space efficiency
</code></pre>
<pre><code>1）布隆过滤器：布隆过滤器[16]是一个概率性的数据结构，它可以确定元素是否存在于集合中。 布隆过滤器没有漏报，但可能有误报。 如果Bloom过滤器返回false，则元素绝对不在集合中； 如果Bloom过滤器返回true，该元素可能在集合中。 与其他实现相同功能的数据结构相比，布隆过滤器具有高空间效率的优势。
</code></pre>
<pre><code>A Bloom filter contains a bit array of length m (initially
containing all 0’s) and uses k different hash functions. To add
an element to a Bloom filter, the k hash functions are applied
to the element. The output of each hash function is a position
in the bit array, which is then set to 1. Therefore, at most k
bits will be set for each added element. To query an element,
the same k hash functions are applied to the element. If the
corresponding bits are all set, then the element may be in the
set; otherwise, the element is definitely not in the set. The false
positive rate of a filter is determined by the size of the set, the
length of the bit array, and the hash functions are being used.
</code></pre>
<pre><code>布隆过滤器包含长度为m的位数组（最初全为0），并使用k个不同的哈希函数。 为了添加一个元素到布隆过滤器，将作用k个哈希函数到该元素。 每个哈希函数的输出是位数组中的某一个位置，然后将其设置为1。因此，每次添加元素时最多k个比特位被设置为1。 要查询元素时，相同的k个哈希函数作用于该元素，如果相应的比特位都已设置，则元素可能在集合里; 否则，该元素绝对不在集合中。误报率取决于集合的大小，位数组的长度以及使用的哈希函数。
</code></pre>
<pre><code>Universal hashing [17] is a good candidate for our Bloom
filter approach as it requires only arithmetic operators (which
S3 Select supports) and represents a family of hash functions.
The hash functions that we use can be generalized as:
</code></pre>
<pre><code>全域哈希[17]是我们Bloom过滤器的一个很好的候选方法，因为它只需要算术运算（S3 Select支持），并代表一系列哈希函数。
我们使用的哈希函数可以概括为：
</code></pre>
<p><img src="https://zhangqu-oss.oss-cn-zhangjiakou.aliyuncs.com/img/image-20210512110847257.png" alt="image-20210512110847257"></p>
<pre><code>Given a desired false positive rate p, the number of hash
functions kp and the length of the bit array mp are determined
by the following formulas [18], where s is the number of
elements in the set.
</code></pre>
<pre><code>给定理想的误报率p，那么哈希函数的数量kp和位数组的长度mp可以通过以下公式进行计算[18]，其中s是集合中的元素。
</code></pre>
<p><img src="https://zhangqu-oss.oss-cn-zhangjiakou.aliyuncs.com/img/image-20210512111101409.png" alt="image-20210512111101409"></p>
<h4 id="1-6-1-2、PushdownDB里的布隆连接"><a href="#1-6-1-2、PushdownDB里的布隆连接" class="headerlink" title="1.6.1.2、PushdownDB里的布隆连接"></a>1.6.1.2、PushdownDB里的布隆连接</h4><pre><code>Bloom filters are usually
processed using bitwise operators. However, since S3 Select
does not support bitwise operators or binary data, an alternative is required that not only represents the bit array but
can be tested for the presence of a set bit. In PushdownDB,
we use strings of 1’s and 0’s to represent the bit array. The
following example shows what an S3 Select query containing
a Bloom filter would look like. The arithmetic expression on
attr within the SUBSTRING function is the hash function
on attr.
</code></pre>
<pre><code>布隆过滤器通常使用按位运算操作进行处理。 但是，由于S3 Select不支持位运算操作和二进制数据，因此需要一个替代数据结构，它不仅可以表示位数组而且还
可以测试设置位的存在性。 在PushdownDB中，我们使用1和0的字符串表示位数组。以下示例展示了一个S3 Select查询所包含的内容（就像一个布隆过滤器）。在SUBSTRING函数中，attr上的算术表达式就是attr上的哈希函数。
</code></pre>
<p><img src="https://zhangqu-oss.oss-cn-zhangjiakou.aliyuncs.com/img/image-20210512111920727.png" alt="image-20210512111920727"></p>
<pre><code>With Bloom join, the first table (typically the smaller one) is
loaded with filtering and projection pushed to S3. The returned
tuples are used to construct both the Bloom filter and the hash
tables. The Bloom filter is then sent to S3 to load the second
table. The returned tuples then probe the hash table to finish
the join operation.
</code></pre>
<pre><code>使用Bloom连接时，第一个表（通常是较小的表）被加载下推到S3的过滤和投影之后的数据。 返回的元组用于构造Bloom过滤器和哈希表。 然后将Bloom过滤器发送到S3以加载第二个表。 返回的元组探测哈希表以完成连接操作。
</code></pre>
<pre><code>The current implementation of Bloom join supports only
integer join attributes. This is because the hash functions
only support integer data types at present. A more general
support for hashing in the S3 Select API would enable Bloom
joins on arbitrary attributes. In fact, while algorithms exist
for hashing variable-length strings, they require looping and/or
array processing operators that are not currently available to S3
Select queries. Additionally, since the bit array is represented
using 1 and 0 characters, the bit array is much larger than it
would be if S3 Select had support for binary data or bitwise
operators to test the presence of a set bit. We believe that
extending the S3 Select interface in this fashion would be
beneficial in our Bloom join algorithm, and perhaps elsewhere.
</code></pre>
<pre><code>Bloom联接的当前实现仅支持整数联接属性。 这是因为哈希函数目前仅支持整数数据类型。 对S3 Select API中的哈希更一般的支持是连接任意属性。 实际上，虽然存在算法可以散列可变长度的字符串，它们需要循环或者S3选择查询当前不支持的数组处理操作。 另外，由于位数组使用字符0和1表示，如果S3 Select支持二进制数据或按位
操作测试是否存在设置位，位数组将会比现在大得多。我们相信以这种方式扩展S3 Select接口将会有益于我们的Bloom联接算法，或许还有其他方面也可以。
</code></pre>
<p><img src="https://zhangqu-oss.oss-cn-zhangjiakou.aliyuncs.com/img/image-20210512113250822.png" alt="image-20210512113250822"></p>
<pre><code>图2：Customer选择性-性能和成本变化（改变Customer表的选择性时）。
</code></pre>
<pre><code>Figure 2 shows the runtime and cost of different join
algorithms as the selectivity on the customer table changes.
Baseline and filtered joins perform similarly, which is expected
since they only apply selection to the smaller customer table
and load the entire orders table, which incurs the same large amount of network traffic. Bloom join performs significantly
better than either as the high selectivity on the first table is
encapsulated by the Bloom filter, which significantly reduces
the number of returned rows for the larger orders table. As the
predicate on the customer table becomes less selective, Bloom
joins performance degrades as fewer records are filtered by
the Bloom filter. Bloom join is cheaper than the other two
algorithms with high selectivity, although the cost advantage
is not as significant as the runtime advantage.
</code></pre>
<pre><code>图2显示了不同连接算法的运行时间和成本的变化（随着Customer表上的选择性的变化）。基准连接和过滤连接的性能类似，这是预期的。因为它们仅将选择应用于较小的Customer表并加载整个订单表，这会产生相同数量的网络流量。Bloom Join比任何一个表现得更出色，因为第一张表上的高选择性被Bloom过滤器封装，这可以显著减少
较大的订单表返回的行数。随着Customer表上的谓词变得越来越少，Bloom联接性能降低，因为布隆过滤器过滤的记录更少了。Bloom Join比法其他两个具有高选择性的算法更便宜，尽管成本优势没有运行时间优势那么重要。
</code></pre>
<h3 id="1-6-2、性能评估"><a href="#1-6-2、性能评估" class="headerlink" title="1.6.2、性能评估"></a>1.6.2、性能评估</h3><pre><code>We compare the runtime and cost of the three join algorithms: baseline, filtered, and Bloom joins. Our experiments use the customer and orders tables from the TPC-H
benchmark with a scale factor of 10. The following SQL
query will be used for evaluation. Our experiments will
sweep two parameters in the query, upper_c_acctbal
and upper_o_orderdate, with their default values being
−950 and None, respectively.
</code></pre>
<pre><code>我们比较了三种联接算法的运行时间和成本：基准联接，过滤联接和Bloom联接。 我们的实验使用TPC-H的Customer和Orders表（以比例因子10为基准）。以下SQL
查询将用于评估。 我们的实验将扫描查询中的两个参数upper_c_acctbal和upper_o_orderdate，其默认值分别为−950和None。
</code></pre>
<p><img src="https://zhangqu-oss.oss-cn-zhangjiakou.aliyuncs.com/img/image-20210512114156004.png" alt="image-20210512114156004"></p>
<p><img src="https://zhangqu-oss.oss-cn-zhangjiakou.aliyuncs.com/img/image-20210512193155836.png" alt="image-20210512193155836"></p>
<pre><code>The results are shown in Figure 3. Filtered join performs
significantly better than baseline join when the filter on the orders table is selective. The performance advantage disappears
when the filter becomes less selective. Bloom join performs
better and remains fairly constant as the number of records
returned from the orders table remains small due to the Bloom
filter. The cost of Bloom join is either comparable or cheaper
than the alternatives
</code></pre>
<pre><code>结果如图3所示。当orders表上的过滤器处于高选择性时，其性能明显优于基线连接。当过滤器的选择性降低时，性能优势消失了。由于Bloom过滤器，布隆连接执行得更好，并且保持稳定的从订单表返回的记录数量。相比其他选择Bloom连接的成本是相当的或者更便宜的。
</code></pre>
<p><img src="https://zhangqu-oss.oss-cn-zhangjiakou.aliyuncs.com/img/image-20210512192940211.png" alt="image-20210512192940211"></p>
<pre><code>Figure 4 shows the runtime and cost of baseline and filtered
join as well as Bloom join with different false positive rates.
We can see that the best performance and cost numbers can
be achieved when the false positive rate is 0.01. When the
false positive rate is low, the Bloom filter is large in size,
increasing the computation requirement in S3 Select. When
the false positive rate is high, the Bloom filter is less selective,
meaning more data will be returned from S3. A rate of 0.01
strikes a balance between these two factors.
</code></pre>
<pre><code>图4显示了基线连接和过滤连接的运行时间和成本以及具有不同误报率的Bloom联接。我们可以看到，在误报率为0.01时达到最佳性能和最低成本。当误报率低的时候，布隆过滤器大小比较大，这增加S3 Select中的计算要求。当误报率很高时，布隆过滤器的选择性较低，这意味着将从S3返回更多数据。误报率0.01在这两个因素之间取得平衡。
</code></pre>
<h2 id="1-7、group-by"><a href="#1-7、group-by" class="headerlink" title="1.7、group by"></a>1.7、group by</h2><pre><code>The current S3 Select supports simple aggregation on individual attributes but not with a group-by clause. Pushing a
group-by aggregation to S3 is desirable as it can significantly reduce network traffic. In this section, we explore designs of
group-by algorithms that leverage S3 Select.
</code></pre>
<pre><code>当前的S3 Select支持在单个属性上进行简单聚合，但不支持group-by子句。 下推一个group by聚合到S3是令人向往的，因为它可以显着减少网络流量。 在本节中，我们将探讨以下方面的设计：利用S3 Select的分组算法。
</code></pre>
<pre><code>Group-by can be performed at the server-side by loading all
data from S3 directly (Server-side group-by) or loading S3 data
using a predicate (Filtered group-by). Both implementations
are straightforward. Therefore, we focus our discussion on two
other algorithms that are less obvious to implement but deliver
better performance — S3-side group-by and Hybrid group-by.
</code></pre>
<pre><code>分组可以通过直接从S3加载所有数据（服务器端group by）或者使用谓词（过滤group by）加载S3数据，在服务端被执行。 两种实现都很简单。 因此，我们将讨论重点放在两个其他不太容易实现但有更好性能的算法-S3端分组和混合分组。
</code></pre>
<h3 id="1-7-1、S3端分组"><a href="#1-7-1、S3端分组" class="headerlink" title="1.7.1、S3端分组"></a>1.7.1、S3端分组</h3><pre><code>The S3-side group-by algorithm pushes the group-by logic
entirely into S3 and thus minimizes the amount of network
traffic. We use the following query to demonstrate how the
algorithm works. It computes the total account balance for
each nation in the customer table.
</code></pre>
<pre><code>S3端分组算法下推整个分组逻辑到S3中，从而最大程度地减少网络流量。 我们使用以下查询来说明算法如何工作。 它Customer表中的nation进行分组，计算每个nation的总帐户余额。
</code></pre>
<p><img src="https://zhangqu-oss.oss-cn-zhangjiakou.aliyuncs.com/img/image-20210512115721954.png" alt="image-20210512115721954"></p>
<pre><code>The first phase of execution collects the values for the
groups in the group-by clause. For the example query, we need
to find the unique values of c_nationkey. This is accomplished by running a projection using S3 Select to return only
the c_nationkey column (i.e., SELECT c_nationkey
FROM customer). The compute node then finids unique
values in the column
</code></pre>
<pre><code>执行的第一阶段收集group by子句中的分组。 对于示例查询，我们需要查找c_nationkey的所有唯一值。 这是通过使用S3 Select（仅返回）来运行投影仅返回c_nationkey列来完成的（即SELECT c_nationkey FROM customer）。 然后，计算节点将确定唯一列中的值。
</code></pre>
<pre><code>In the second phase of execution, PushdownDB requests
S3 to perform aggregation for each individual group that the
first phase identified. For example, if the unique values of
c_nationkey are 0 and 1, then the following query will be
sent to S3 in phase 2.
</code></pre>
<pre><code>在执行的第二阶段，PushdownDB请求S3对每个第一阶段确认的单独的组执行聚合。 例如，如果c_nationkey是0和1，那么下面的查询将在阶段2中发送到S3。
</code></pre>
<p><img src="https://zhangqu-oss.oss-cn-zhangjiakou.aliyuncs.com/img/image-20210512120611853.png" alt="image-20210512120611853"></p>
<pre><code>The first and second returned numbers are the total customer
balance for c_nationkey = 0 and 1, respectively. The number of columns in the S3 Select response equals the number
of unique groups multiplied by the number of aggregations.
The query execution node converts the results into the right
format and returns them to the user.
</code></pre>
<pre><code>返回的第一个和第二个数字分别是c_nationkey为0和1的总余额。 S3 Select response中的列数等于唯一组的数量乘以聚合的数量。
查询执行节点将结果转换为合适的格式并将其返回给用户。
</code></pre>
<h3 id="1-7-2、混合分组"><a href="#1-7-2、混合分组" class="headerlink" title="1.7.2、混合分组"></a>1.7.2、混合分组</h3><pre><code>In practice, many data sets are highly skewed, with a few
large groups containing the majority of rows, and many groups
containing only a few rows. For these workloads, S3-side
group-by will likely deliver bad performance since the large
number of groups leads to long S3 Select queries. To solve
this problem, we propose a hybrid group-by algorithm that
distinguishes groups based on their size. Hybrid group-by
pushes the aggregation on large groups to S3, thus eliminating
the need for transferring large amounts of data. Small groups,
on the other hand, are aggregated by the query execution
nodes.
</code></pre>
<pre><code>在实践中，许多数据集高度偏斜，只有少数几个分组包含大量行，其他大部分分组只包含少数几行。 对于这些工作负载，S3端分组可能产生比较差的性能，因为分组太多会导致较长的S3 Select查询。为了解决这一问题，我们提出了一种混合分组算法，该算法根据组的大小分组。 混合分组将大组上的聚合下推到S3，从而消除了传输大量数据的需要。另一方面，小组由查询执行节点进行聚合。
</code></pre>
<pre><code>Similar to S3-side group-by, hybrid group-by also contains
two phases. In the first phase, however, hybrid group-by does
not scan the entire table, but only a sample of rows as they
are sufficient to capture the populous groups. In particular,
PushdownDB scans the first 1% of data from the table.
</code></pre>
<pre><code>类似于S3端分组，混合分组也包含两个阶段。 但是，在第一阶段，混合分组不会扫描整个表，而是只扫描所有行的一个样本（足以获得行很多的分组）。 特别地，
PushdownDB扫描表中前1％的数据。
</code></pre>
<p><img src="https://zhangqu-oss.oss-cn-zhangjiakou.aliyuncs.com/img/image-20210512131152134.png" alt="image-20210512131152134"></p>
<pre><code>Listing 5 shows the S3 Select query for the second phase
of hybrid group-by. Two queries are sent to S3. Q1 runs
remote aggregation for the large groups (in this example,
c_nationkey = 0), similar to the second phase of S3-side
group-by. Q2 is sent for loading rows belonging to the rest of
the groups from S3. Aggregation for these rows is performed
locally at the compute node.
</code></pre>
<pre><code>List5显示了混合分组第二阶段的S3 Select查询。 两个查询被发送到S3。 第一个查询运行大组的远程聚合（在此示例中，c_nationkey = 0），类似于S3-side分组的第二阶段。 第二个查询加载S3分组的剩余行。 这些行的聚合在计算节点本地执行。
</code></pre>
<h3 id="1-7-3、Performance-Evaluation"><a href="#1-7-3、Performance-Evaluation" class="headerlink" title="1.7.3、Performance Evaluation"></a>1.7.3、Performance Evaluation</h3><p><img src="https://zhangqu-oss.oss-cn-zhangjiakou.aliyuncs.com/img/image-20210512194220209.png" alt="image-20210512194220209"></p>
<pre><code>Figure 5 shows the runtime and cost per query for different
group-by algorithms, as the number of groups changes from
2 to 32. Each query performs aggregation over four columns.
The performance of server-side group-by and filtered group-by does not change with the number of groups, because both
algorithms must load all the rows from S3 to the compute
node. However, filtered group-by loads only the four columns
on which aggregation is performed while server-side group-by loads all the columns. This explains the 64% higher
performance of filtered over server-side group-by. S3-side
group-by performs 4.1× better than filtered group-by when
there are only a few unique groups. Performance degrades,
however, when more groups exist. This is due to the increased
computation overhead that is performed by the S3 servers.
</code></pre>
<pre><code>图5显示了不同分组算法每个查询的运行时间和成本，随着分组数从2增加到32。每个查询在四个列上执行聚合。服务器端group-by和filter group-by的性能不会随组数的变化而改变，因为这两个算法都必须将S3中的所有行加载到计算节点。但是，过滤分组仅加载聚合时用到的四个列，而服务器端group by加载所有列。这解释了为什么过滤分组比服务端分组算法性能高出了64％。当只有几个唯一组时，S3端分组算法比过滤分组性能高出了4.1倍。但是当存在更多组时，性能就下降了。这是由于增加了S3服务器执行的计算开销。
</code></pre>
<p><img src="https://zhangqu-oss.oss-cn-zhangjiakou.aliyuncs.com/img/image-20210512195028379.png" alt="image-20210512195028379"></p>
<pre><code>We first investigate an important parameter in hybrid group-by: how many groups should be aggregated at S3 vs. server
side. Figure 6 shows the runtime of server-side and S3-side aggregation while increasing the number of groups aggregated in
S3. The bars show the runtime and the line shows the number
of bytes returned from S3. More S3-side aggregation increases
the execution time of the part of query executed at S3, but reduces the amount of data transferred over the network. The
final execution time is determined by the maximum of the
two bars shown in Figure 6. Overall, having 6 to 8 groups
aggregated in S3 offers the best performance.
</code></pre>
<pre><code>我们首先调查混合分组中的一个重要参数：在S3与服务器端上应聚合多少个分组。 
图6显示了服务器端和S3端聚合的运行时间，同时增加了S3端的分组数量。 条形图显示运行时间，而折线显示从S3返回的字节数。 更多的S3端聚合增加了在S3端执行的查询部分的执行时间，但减少了通过网络传输的数据量。最终执行时间取决于图6中显示了两个条形图的较大值。总体而言，在S3中有6到8个分组聚合时，性能最优。
</code></pre>
<p><img src="https://zhangqu-oss.oss-cn-zhangjiakou.aliyuncs.com/img/image-20210512195815937.png" alt="image-20210512195815937"></p>
<pre><code>Figure 7 shows the performance and cost of three group-by
algorithms as the level of skew in group sizes increases. Across
all levels of skew, the performance and cost of server-side
and filtered group-by remain the same. In both algorithms, the
amount of data loaded from S3 and the computation performed
on the server are independent of data distribution. When
the workload has high skew, the performance advantage of
pushing group-by to S3 is evident. With θ = 1.3, hybrid group-by performs 31% better than filtered group-by. However,
hybrid group-by does not have a cost advantage over the other
two algorithms, since it has to scan the table one more time
than filtered group-by. This extra table scan can be avoided
by improving the interface of S3 Select.
</code></pre>
<pre><code>图7显示了三种分组算法的性能和成本的变化（随着分组大小的倾斜程度增加时）。可以看到，随着倾斜程度的增加，服务器端分组和过滤分组的性能和成本保持不变。 在这两种算法中，从S3加载的数据量和执行在服务器上的计算独立于数据分发。当工作负载倾斜程度高时，将groupby下推到S3的性能优势是明显的。在θ= 1.3的情况下，混合分组算法的性能要比过滤分组高31％。 然而，混合分组算法相比其他两个分组算法并没有成本优势，因为它比过滤分组算法多扫描一次表。这可以通过改进S3 Select的接口来避免这种额外的表扫描。
</code></pre>
<h2 id="1-8、TOP-K"><a href="#1-8、TOP-K" class="headerlink" title="1.8、TOP-K"></a>1.8、TOP-K</h2><pre><code>Top-K is a common operator that selects the maximum or
minimum K records from a table according to a specified
expression. In this section, we discuss a sampling-based approach that can significantly improve the efficiency of top-K
using S3 Select.
</code></pre>
<pre><code>Top-K是根据指定的表达式从一张表里选择最大或最小的K条记录的常用操作。在本节中，我们讨论一个基于采样的方法，该方法使用S3 Select可以显著提高top-K的效率。
</code></pre>
<h3 id="1-8-1、基于采样的TOP-K算法"><a href="#1-8-1、基于采样的TOP-K算法" class="headerlink" title="1.8.1、基于采样的TOP-K算法"></a>1.8.1、基于采样的TOP-K算法</h3><pre><code>The number of records returned by a top-K query, K, is
typically much smaller than the total number of records in the
table, N. Therefore, transferring the entire table from S3 to the server is inherently inefficient. We designed a sampling-based two-phase algorithm to resolve this inefficiency: the first
phase samples the records from the table and decides what
subset of records to load in the second phase; then in the
second phase, the query execution node loads this subset of
records and performs the top-K computation on it. We use the
following example query for the rest of the discussion.
</code></pre>
<pre><code>TOP-K查询返回的记录数K通常比记录中的记录总数N小得多。因此，将整个表从S3传输到服务器本质上效率低下。 我们设计了一种基于采样的两阶段算法来解决这种效率低下的问题：第一阶段对表中的记录进行采样并确定在第二阶段加载的记录子集； 然后在第二阶段，查询执行节点加载该子集并对其执行top-K计算。对于剩下的讨论我们使用下面的示例查询。
</code></pre>
<p><img src="https://zhangqu-oss.oss-cn-zhangjiakou.aliyuncs.com/img/image-20210512132653209.png" alt="image-20210512132653209"></p>
<pre><code>During the first phase, we obtain a conservative estimate
of a subset that must contain the top-K records. Specifically,
the system loads a random sample of S (&gt; K) records from
the S3 and uses the Kth smallest l_extendedprice as
the threshold. If the data in the table is random, then the
algorithm can simply request the first S records from the table.
Otherwise, if the data distribution in the l_extendedprice
column is not random, then a random sample of S records
can be obtained by requesting a number of data chunks using
random byte offsets from the data table. The sampling process
guarantees that the top-K records must be below the threshold,
since we have already seen K records below the threshold in
the sample. In the second phase, the algorithm uses S3 Select
to load records below the threshold.
</code></pre>
<pre><code>在第一阶段，我们获得了保守必须包含前K个记录的子集的估计。 具体来说，系统从S3中加载S（&gt; K）个记录的随机样本，并使用第K小的l_extendedprice作为
阈值。 如果表中的数据是随机的，则该算法可以简单地从表中请求第一组S个记录。否则，如果数据分布在l_extendedprice中列不是随机的，则S个记录的随机样本
可以通过使用数据表中的随机字节偏移量请求多个数据块来获得。 采样过程确保前K条记录必须低于阈值，因为我们在样本里已经看到低于阈值的K条记录了。 在第二阶段，算法使用S3 Select加载低于阈值的记录。
</code></pre>
<pre><code>The number of records returned in the second phase should
be between K and N. The algorithm then uses a heap to select
the top-K records from all returned records.
</code></pre>
<pre><code>第二阶段返回的记录数应介于K和N之间。然后该算法使用堆来选择所有返回的记录中的前K个记录。
</code></pre>
<h3 id="1-8-2、分析"><a href="#1-8-2、分析" class="headerlink" title="1.8.2、分析"></a>1.8.2、分析</h3><pre><code>An important parameter in the sampling-based algorithm is
the sample size S, which is crucial to the efficiency of the
algorithm. A small S means the second phase will load more
data from S3, while a large S means the sampling phase will
take significant time. The goal of the sampling-based top-K
algorithm is to reduce data traffic from S3. We can obtain
the sample size that minimizes data traffic using the following
analysis:
</code></pre>
<pre><code>基于采样的算法中的一个重要参数是样本大小S，这对于算法的效率是至关重要的。 较小的S表示第二阶段将加载更多来自S3的数据，而较大的S表示采样阶段将
花费大量时间。 基于采样的TOP-K算法目标是减少来自S3的数据流量。 我们可以使用以下分析获得最大程度地减少数据流量的样本大小：
</code></pre>
<pre><code>Assume each row contains B bytes, the table contains
N rows, and the sample contains S rows. We also assume
that only a fraction (α ≤ 1) of the bytes in a record is
needed during the sampling phase, because the expression
in the ORDER BY clause does not necessarily require all
the columns. We assume the sampling process is uniformly
random. The total number of bytes loaded from S3 during the
first phase is:
</code></pre>
<pre><code>假设每一行包含B个字节，表包含N行，样本包含S行。 我们还假设一条记录中仅一小部分字节（α≤1）是在采样阶段需要的，因为在ORDER BY子句中不一定需要全部
列。 我们假设采样过程是随机均匀的。 第一阶段期间从S3加载的字节总数是：
</code></pre>
<p><img src="https://zhangqu-oss.oss-cn-zhangjiakou.aliyuncs.com/img/image-20210512145802805.png" alt="image-20210512145802805"></p>
<pre><code>The Kth record from the sample is selected as the threshold.
Based on the random sampling assumption, the system loads
KN/S records in phase 2. Therefore, the total number of bytes
loaded from S3 in phase 2 is:
</code></pre>
<pre><code>选择样本中的第K条记录作为阈值。基于随机抽样假设，系统在阶段2中加载KN / S记录。因此，在阶段2中从S3加载的总字节数是：
</code></pre>
<p><img src="https://zhangqu-oss.oss-cn-zhangjiakou.aliyuncs.com/img/image-20210512150058640.png" alt="image-20210512150058640"></p>
<p><img src="https://zhangqu-oss.oss-cn-zhangjiakou.aliyuncs.com/img/image-20210512150359626.png" alt="image-20210512150359626"></p>
<pre><code>The total amount of data loaded from S3 (D) is the sum of
data loaded during both phases:
</code></pre>
<pre><code>从S3（D）加载的数据总量是在两个阶段中加载的数据量之和：
</code></pre>
<p><img src="https://zhangqu-oss.oss-cn-zhangjiakou.aliyuncs.com/img/image-20210512150636642.png" alt="image-20210512150636642"></p>
<p><img src="https://zhangqu-oss.oss-cn-zhangjiakou.aliyuncs.com/img/image-20210512150728578.png" alt="image-20210512150728578"></p>
<pre><code>可以通过上述公式找到使D最小的S值： 这使S = sqrt(KN/α)。 给定固定的表大小，α越小S越大。这是因为如果采样不会消耗大量带宽，值得采样更多记录以提高整体带宽效率。
</code></pre>
<h3 id="1-8-3、Performance-Evaluation"><a href="#1-8-3、Performance-Evaluation" class="headerlink" title="1.8.3、Performance Evaluation"></a>1.8.3、Performance Evaluation</h3><p><img src="https://zhangqu-oss.oss-cn-zhangjiakou.aliyuncs.com/img/image-20210512200724585.png" alt="image-20210512200724585"></p>
<pre><code>In Figure 8a, each bar shows the runtime of a query at
a particular sample size. Each bar is broken down into two
portions: the sampling phase (phase 1) and the scanning phase
(phase 2). The line shows the total amount of data returned
from S3 to the server.
</code></pre>
<pre><code>在图8a中，每个条形图都显示了在特定的样本量大小时查询的运行时间。 每个条形图分为两个阶段：采样阶段（阶段1）和扫描阶段（阶段2）。折线显示了从S3到服务器返回的数据总量。
</code></pre>
<pre><code>Figure 8b shows the query cost with varying sample size.
Most of the cost is due to data scanning, with most of this
due to the scanning phase (phase 2).
</code></pre>
<pre><code>图8b显示了具有不同样本大小的查询成本。大部分成本是由于数据扫描造成的，其中大部分是在扫描阶段（阶段2）。
</code></pre>
<p><img src="https://zhangqu-oss.oss-cn-zhangjiakou.aliyuncs.com/img/image-20210512201225720.png" alt="image-20210512201225720"></p>
<pre><code>Figure 9a shows that for both algorithms, runtime increases
as K increases. This is because a larger K requires a bigger
heap and also more computation at the server side. The
sampling-based top-K algorithm is consistently faster than the
server-side top-K due to the reduction in the amount of data
loaded from S3.
</code></pre>
<pre><code>图9a显示，对于这两种算法，运行时间都会随着K的增加而增加。这是因为更大的K需要更大的堆以及在服务器端进行更多计算。这种基于采样的top-K算法始终比服务器端的TOP-K算法快，因为从S3加载的数据量减少了。
</code></pre>
<pre><code>In Figure 9b, we observe that the sampling-based top-K
algorithm is also consistently cheaper than server-side top-K.
When K is small, the majority of the cost in the samplingbased algorithm is data scanning. As K increases, the data
scan cost does not significantly change, but the computation
cost increases due to the longer time spent obtaining the top-K
using the heap.
</code></pre>
<pre><code>在图9b中，我们观察到基于采样的top-K算法始终比服务器端的top-K算法成本低。当K较小时，基于采样的算法中的大部分成本是数据扫描。随着K的增加，数据
扫描成本没有明显变化，但是计算成本增加了，因为使用堆获得TOP-K个数的时间增加了。
</code></pre>
<h2 id="1-9、TPC-H结果"><a href="#1-9、TPC-H结果" class="headerlink" title="1.9、TPC-H结果"></a>1.9、TPC-H结果</h2><pre><code>In this section, we evaluate a representative query for each
individual operator discussed in Sections IV – VII, as well as
a subset of the TPC-H queries. Each experiment evaluates the
following two configurations:
</code></pre>
<pre><code>在本节中，针对第四节至第七节中讨论的每个操作，我们评估了一个具有代表性的查询，以及TPC-H查询的子集。 每个实验都会评估以下两种配置：
</code></pre>
<p><img src="https://zhangqu-oss.oss-cn-zhangjiakou.aliyuncs.com/img/image-20210512170722568.png" alt="image-20210512170722568"></p>
<pre><code>PushdownDB (Baseline): This is the PushdownDB implementation described in Section III but not including S3
Select features. The server loads the entire table from S3 and
performs computation locally.
</code></pre>
<pre><code>PushdownDB（基线）：这是第三节中描述的PushdownDB实现，但不包括S3 Select功能。 服务器从S3加载整个表后在本地执行计算。
</code></pre>
<pre><code>PushdownDB (Optimized): The PushdownDB that includes the optimizations discussed in this paper.
The experiments use the 10 GB TPC-H dataset. The results
are summarized in Figure 10. From left to right, the figure
shows performance and cost of individual operators (shaded
in green), TPC-H queries (shaded in yellow), and geometric
mean (shaded in light blue). The geo-mean cost only contains
the total cost, not broken down into individual components.
</code></pre>
<pre><code>PushdownDB（优化）：PushdownDB包含了本文中讨论的优化。
实验使用10 GB TPC-H数据集。 结果总结在图10中。从左到右，该图显示各个操作的性能和成本（绿色阴影），TPC-H查询（黄色阴影）和几何均值（浅蓝色阴影）。 几何均值成本仅包含总成本，而不是细分为各个组成部分的成本。
</code></pre>
<pre><code>As we can see, the optimizations discussed in this paper
can significantly improve the performance of various types of
queries. On average, the optimized PushdownDB outperforms
the baseline PushdownDB by 6.7× and reduces the cost by
30%. We assume a database can use various statistics of the
underlying data to determine which algorithm to use for a
particular query. Dynamically determining which optimization
to use is orthogonal to and beyond the scope of this paper
</code></pre>
<pre><code>如我们所见，本文讨论的优化可以显著提高各种类型查询的性能。 平均而言，优化的PushdownDB的性能比基线PushdownDB优6.7倍，成本降低了30％。 我们假设数据库可以使用各种基础统计信息，以确定对特定查询使用哪种算法。 动态确定使用哪种优化和统计学相关，这超出了本文的范围
</code></pre>
<pre><code>To validate these results, we also compared the execution time of PushdownDB to Presto, a highly optimized
cloud database written in Java. We use Presto v0.205 as a
performance upper bound when S3 Select is not used. On
average, the runtime of baseline PushdownDB is slower than
Presto by less than 2×, demonstrating that the code base of
PushdownDB is reasonably well optimized. The optimized
PushdownDB outperforms Presto by 3.4×.
</code></pre>
<pre><code>为了验证这些结果，我们还将PushdownDB的执行时间与Presto（一个高度优化的用Java编写的云数据库）进行了比较。不使用S3 Select时，我们使用Presto v0.205作为性能上限。平均而言，基准PushdownDB的运行时间慢于Presto不到2倍，这表明PushdownDB的代码库进行了合理的优化。优化的PushdownDB的性能比Presto高3.4倍。
</code></pre>
<h2 id="1-10、PARQUET实验"><a href="#1-10、PARQUET实验" class="headerlink" title="1.10、PARQUET实验"></a>1.10、PARQUET实验</h2><h2 id="1-11、S3-Select的局限性"><a href="#1-11、S3-Select的局限性" class="headerlink" title="1.11、S3 Select的局限性"></a>1.11、S3 Select的局限性</h2><pre><code>So far, we have demonstrated substantial performance improvement on common database operators by leveraging S3
Select. In this section, we present a list of limitations of the
current S3 Select features and describe our suggestions for
improvement.
</code></pre>
<pre><code>到目前为止，我们已经证明了利用S3 Select可以提高普通数据库操作的性能。 在本节中，我们列出了当前的S3选择功能的局限性并描述了我们改进的建议。
</code></pre>
<h3 id="1-11-1、Suggestion-1-Multiple-byte-ranges-for-GET-requests"><a href="#1-11-1、Suggestion-1-Multiple-byte-ranges-for-GET-requests" class="headerlink" title="1.11.1、Suggestion 1: Multiple byte ranges for GET requests"></a>1.11.1、Suggestion 1: Multiple byte ranges for GET requests</h3><pre><code>The indexing algorithm discussed in Section IV-A sends HTTP
GET requests to S3 to load records from the table; each request
asks for a specified range of bytes that are derived from an
index table lookup. According the S3 API [20], the current
GET request to S3 supports only a single byte range. This
means that a large number of GET requests have to be sent if
many records are selected by a query. Excessive GET requests
can hurt performance as shown in Figure 1. Allowing a single
GET request to contain multiple byte ranges, which is allowed
by HTTP, can significantly reduce the cost of HTTP request
processing in both the server and S3.
</code></pre>
<pre><code>IV-A节中讨论的索引算法发送HTTP GET请求到S3以从表中加载记录； 每个请求要求从一个索引表里查找指定范围的字节数据。 根据S3 API [20]，当前对S3的GET请求仅支持单个字节范围。 这表示如果查询选择了许多记录，必须发送大量的GET请求。过多的GET请求会损害性能，如图1所示。允许一个GET请求包含多个字节范围，HTTP是允许的，这可以大大降低HTTP请求的成本，通过在服务器和S3中共同进行处理。
</code></pre>
<h3 id="1-11-2、Suggestion-2-Index-inside-S3"><a href="#1-11-2、Suggestion-2-Index-inside-S3" class="headerlink" title="1.11.2、Suggestion 2: Index inside S3"></a>1.11.2、Suggestion 2: Index inside S3</h3><pre><code>A more thorough solution to
the indexing problem is to build the index structures entirely
inside S3. This avoids many network messages between S3
and the server that are caused by accesses to the index data
structure during an index lookup. S3 can handle the required
logic on behalf of the server, like handling hash collisions in
a hash index or traversing through the tree in a B-tree index.
</code></pre>
<pre><code>对于索引问题更彻底的解决方案是完全建立索引结构在S3内部。 这避免了S3和服务器之间的许多网络消息，这是由于在索引查找期间访问索引数据结构而导致的。 S3可以代表服务器处理所需的的逻辑，例如在哈希索引中处理哈希冲突或遍历B树索引中的树。
</code></pre>
<h3 id="1-11-3、Suggestion-3-More-efficient-Bloom-filters"><a href="#1-11-3、Suggestion-3-More-efficient-Bloom-filters" class="headerlink" title="1.11.3、Suggestion 3: More efficient Bloom filters"></a>1.11.3、Suggestion 3: More efficient Bloom filters</h3><pre><code>Bloom filters
can substantially improve performance of join queries, as
demonstrated in Section V. A Bloom filter is represented
using a bit array for space efficiency. The current S3 Select,
however, does not support bit-wise operators. Our current
implementation of a Bloom join in S3 Select uses a string
of 0s and 1s to represent the bit array, which is space- and
computation-inefficient. We suggest that the next version of S3
Select should support efficient bit-wise operators to improve
the efficiency of Bloom join.
</code></pre>
<pre><code>布隆过滤器可以大大提高联接查询的性能，正如在第五节中演示的。布隆过滤器使用位数组进行表示来提高空间效率。但是当前的S3 Select不支持按位运算。我们目前
S3 Select中Bloom联接的实现使用字符串0和1的整数表示位数组，这在空间和计算效率上是低下的。 我们建议S3 Select的下一个版本应该支持高效的按位操作以方便改进Bloom连接的效率。
</code></pre>
<h3 id="1-11-4、Suggestion-4-Partial-group-by"><a href="#1-11-4、Suggestion-4-Partial-group-by" class="headerlink" title="1.11.4、Suggestion 4: Partial group-by."></a>1.11.4、Suggestion 4: Partial group-by.</h3><pre><code>Section VI-B introduced
our hybrid group-by algorithm and demonstrated its superior
performance. Since S3 does not support group-by queries, we
used the CASE clause to implement S3-side group-by, which is
not the most efficient implementation. We suggest adding partial group-by queries to S3 to resolve this performance issue.
Note that pushing an arbitrary group-by query entirely to S3
may not be the best solution, because a large number of groups
can consume significant memory space and computation in S3.
We consider the partial S3-side group-by as an optimization
to the second phase of our current hybrid group-by.
</code></pre>
<pre><code>第VI-B节介绍了我们的混合分组算法，并展示了其优越的性能表现。 由于S3不支持分组查询，因此我们使用CASE子句实现了S3端分组查询，这不是最搞笑的实现。 我们建议向S3添加部分分组查询以解决此性能问题。请注意，将任意分组查询完全下推到S3可能不是最好的解决方案，因为有很多组在S3中可能会占用大量内存空间和计算量。
我们认为部分S3端的分组查询对于目前的混合分组算法的第二阶段是一种优化。
</code></pre>
<h3 id="1-11-5、Suggestion-5-Computation-aware-pricing"><a href="#1-11-5、Suggestion-5-Computation-aware-pricing" class="headerlink" title="1.11.5、Suggestion 5: Computation-aware pricing."></a>1.11.5、Suggestion 5: Computation-aware pricing.</h3><pre><code>Across our
evaluations on the optimized PushdownDB, data scan costs
dominate a majority of queries. In the current S3 Select
pricing model, data scanning costs a fixed amount ($0.002/GB)
regardless of what computation is being performed. Given
that our queries typically require little computation in S3, the
current pricing model may have overcharged our queries. We believe a fairer pricing model is needed, in which the data
scan cost should depend on the workload.
</code></pre>
<pre><code>横看我们对优化的PushdownDB的评估，数据扫描成本在大多数查询占主要地位。 在当前的S3 Select定价模型中，不管正在执行什么计算，数据扫描的成本是固定的（0.002美元/ GB）。鉴于我们的查询通常在S3中只需要很少的计算，当前的定价模式可能对我们的查询收费过高。 我们认为需要一个更公平的定价模式，其中的数据
扫描成本应取决于工作量。
</code></pre>
<h2 id="1-12、相关工作"><a href="#1-12、相关工作" class="headerlink" title="1.12、相关工作"></a>1.12、相关工作</h2><h3 id="1-12-1、In-Cloud-Databases"><a href="#1-12-1、In-Cloud-Databases" class="headerlink" title="1.12.1、In-Cloud Databases"></a>1.12.1、In-Cloud Databases</h3><pre><code>Database systems are moving to the cloud environment
due to cost. Most of these in-cloud databases support storing data within S3. Vertica [21], a traditional column-store
shared nothing database, started to support S3 in its new Eon
mode [22]. Snowflake [2] is a software-as-a-service (SaaS)
database designed specifically for the cloud environment.
Many open-source in-cloud databases have been developed
and widely adopted, examples including Presto [1], Hive [12],
and Spark SQL [13]. Furthermore, AWS offers a few proprietary database systems in the cloud: Athena [23], Aurora [24],
and Redshift [3].
</code></pre>
<pre><code>由于成本关系，数据库系统正在迁移到云环境。大多数这些云数据库都支持在S3内存储数据。 Vertica [21]，一个传统的列存储，share-nothing数据库，开始在其新的Eon模式[22]中支持S3。 Snowflake [2]是一种软件即服务（SaaS）专为云环境设计的数据库。许多开源的云数据库被开发出来并被广泛采用，例如Presto [1]，Hive [12]，和Spark SQL [13]。 此外，AWS在云中提供了一些专有的数据库系统：Athena [23]，Aurora [24]，和Redshift [3]。
</code></pre>
<pre><code>Among the systems mentioned above, Presto, Spark, and
Hive support S3 Select in Amazon Elastic MapReduce (EMR)
in limited form. For example, Presto supports pushing predicates to S3 but does not support data types like timestamp,
real, or double. Furthermore, these systems currently support
only simple filtering operations but not complex ones like join,
group-by, or top-K, which are what PushdownDB focuses on.
</code></pre>
<pre><code>在上述系统中，Presto，Spark和Hive以有限的形式支持Amazon Elastic MapReduce（EMR）中的S3 Select。 例如，Presto支持将谓词推送到S3，但不支持时间戳，
实数或double数据类型。 此外，这些系统目前仅仅支持简单的过滤操作，而不支持复杂的过滤操作（例如连接，分组或top-K），这是PushdownDB所关注的。
</code></pre>
<pre><code>The Spectrum feature of Redshift offloads some query
processing on data stored in S3 to the “Redshift Spectrum
Layer” such that more parallelism can be exploited beyond
the capability of the cluster created by the user. The ideas
discussed in this paper can be applied to the Redshift Spectrum
setting to improve performance of complex database operators.
</code></pre>
<pre><code>Redshift的Spectrum功能减轻了一些查询的负担（通过将存储在S3中的数据处理移到了Redshift的Spectrum层），以便更多并行性能被充分利用（超出了用户创建的集群性能）。 本文讨论的想法可以应用于Redshift Spectrum环境下以提高复杂数据库操作的性能。
</code></pre>
<h3 id="1-12-2、-Database-Machines"><a href="#1-12-2、-Database-Machines" class="headerlink" title="1.12.2、 Database Machines"></a>1.12.2、 Database Machines</h3><pre><code>A line of research on database machines emerged in the
1970s and stayed active for more than 10 years. These systems
contain processors or special hardware to accelerate database
accesses, by applying the principle of pushing computation to
where the data resides.
</code></pre>
<pre><code>在20世纪70年代出现了一系列有关数据库机器的研究，并且活跃了10多年。 这些系统包含处理器或特殊硬件来加速数据库访问，通过应用将计算下推到数据所在的位置的原理。
</code></pre>
<pre><code>The Intelligent Database Machines (IDM) [7] from Britton
Lee separated the functionality of host computers and the
database machine which sits closer to the disks. Much of
a DBMS functionality can be performed on the database
machine, thereby freeing the host computers to perform other
tasks. Grace [25] is a parallel database machine that contains
multiple processors connected to multiple disk modules. Each
disk module contains a filter processor that can perform
selection using predicates and projection to reduce the amount
of data transfer as well as computation in the main processors.
</code></pre>
<pre><code>Britton Lee的智能数据库机（IDM）[7]分离了主机计算机和靠近磁盘的数据库机的功能。许多DBMS功能可以在数据库机上执行，从而解放主机以执行其他任务。 Grace [25]是包含以下内容的并行数据库计算机：多个处理器连接到多个多个磁盘模块。 每个磁盘模块包含一个过滤处理器，它能使用谓词进行选择，并且可以投影来减少
数据传输量以及主处理器中的计算量。
</code></pre>
<pre><code>More recently, in the 2000s, IBM Netezza data warehouse
appliances [9] used FPGA-enabled near-storage processors
(FAST engines) to support data compression, projection, and
row selection. In Oracle’s Exadata [8] database engines, the
storage unit (Exadata Cell) can support predicate filtering,
column filtering, Bloom join, encryption, and indexing among
other functionalities.
</code></pre>
<pre><code>最近，在21世纪初，IBM Netezza数据仓库设备[9]使用了支持FPGA的近存储处理器（FAST引擎）来支持数据压缩，投影和行选择。 在Oracle Exadata [8]数据库引擎中，存储单元（Exadata单元）可以支持谓词过滤，列过滤，Bloom连接，加密和索引等等其他功能。
</code></pre>
<h3 id="1-12-3、Near-Data-Processing-NDP"><a href="#1-12-3、Near-Data-Processing-NDP" class="headerlink" title="1.12.3、Near-Data Processing (NDP)"></a>1.12.3、Near-Data Processing (NDP)</h3><pre><code>Near-data processing has recently attracted much research
interest in the computer architecture community [26]. Techniques have been proposed for memory and storage devices
in various part of the system. Although the techniques in this
paper were proposed assuming a cloud storage setting, many
of them can be applied to the following other settings as well.
</code></pre>
<pre><code>邻近数据处理在计算机体系结构社区最近吸引了很多研究兴趣[26]。 在系统的各个部分已经提出了用于内存和存储设备的技术。 虽然本文提出的各种技术基于云存储环境，但是它们也可以应用于以下其他环境。
</code></pre>
<pre><code>Processing-in-Memory (PIM) [27] exploits computation
near or inside DRAM devices to reduce data transfer between
CPU and main memory, which is a bottleneck in modern
processors. Recent development in 3D-stacked DRAM implements logic at the bottom layer of the memory chip [28],
supporting in-memory processing with lower energy and cost.
</code></pre>
<pre><code>内存中处理（PIM）[27]利用DRAM设备附近或内部的计算来减少CPU和主存之间的数据传输，这是现代处理器的瓶颈。3D堆栈 DRAM的最新发展在内存芯片的底层实现了逻辑[28]，以更低的能源和成本支持in-memory处理。
</code></pre>
<pre><code>While smart disks have been studied in the early 2000s [29],
[30], they have not seen wide adoption due to the limitations
of the technology. The development of FPGAs and SSDs in
recent years has made near storage computing more practical.
Recent studies have proposed to push computation to both
near-storage FPGAs [31], [32] and the processor within an
SSD device [33], [34], [35]. Most of these systems only
focused on simple operators like filter or projection, but did
not study the effect of more complex operators as we do in
PushdownDB.
</code></pre>
<pre><code>尽管在21世纪初期已经研究了智能磁盘[29]，[30]，但由于技术局限性，他们尚未得到广泛应用。 近年来FPGA和SSD的发展让邻近的存储计算变得更加实用。最近的研究提出将计算下推到邻近存储的FPGA [31]，[32]和SSD设备[33]中的处理器，[34]，[35]。 大多数这些系统仅仅关注简单的操作（例如过滤器或投影），而不像我们在PushdownDB里的那样研究更复杂的操作的影响。
</code></pre>
<pre><code>Hybrid shipping techniques execute some query operators
at the client side, where the query is invoked, and some at the
server side, where data is stored [36]. However, near-storage
computing services as S3 do not support complex operators
such as joins. Hybrid shipping does not consider how to push
down only some of the steps involved in the implementation
of a single operator, which is what PushdownDB addresses.
</code></pre>
<pre><code>混合传输技术在客户端（调用查询的地方）执行一些查询操作，还有一些在服务器端（存储数据的地方）[36]。 但是，邻近存储作为S3的计算服务不支持复杂的操作，例如连接。 混合传输不考虑如何下推在单个操作中所涉及实现的仅仅一部分步骤，这就是PushdownDB所解决的问题。
</code></pre>
<h2 id="1-13、结论"><a href="#1-13、结论" class="headerlink" title="1.13、结论"></a>1.13、结论</h2><pre><code>This paper presents PushdownDB, a data analytics engine
that accelerates common database operators by performing
computation in S3 via S3 Select. PushdownDB reduces both
runtime and cost for a wide range of operators, including
filter, project, join, group-by, and top-K. Using S3 Select,
PushdownDB improves the average performance of a subset
of the TPC-H queries by 6.7× and reduces cost by 30%.
</code></pre>
<pre><code>本文介绍了数据分析引擎PushdownDB，它通过S3 Select在S3中执行计算加速了一般的数据库操作。 PushdownDB减少了各种操作的运行时间和成本，包括过滤，投影，连接，分组和TOP-K。使用S3 Select，PushdownDB对于TPC-H查询子集的平均性能提升了6.7倍，成本降低了30％。
</code></pre>

            </div>
            <hr />

            
            <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.88rem;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-large waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fa fa-close"></i></a>
            <h4 class="reward-title">写作不易，客官能否打赏一杯奶茶？</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            

            <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    <div class="social-share" data-disabled="qzone" data-wechat-qrcode-helper="<p>微信里点“发现”->“扫一扫”二维码便可查看分享。</p>"></div>
    
</div>

<script src="/libs/share/js/social-share.min.js"></script>

            

    <div class="reprint" id="reprint-statement">
        <p class="reprint-tip">
            <i class="fa fa-exclamation-triangle"></i>&nbsp;&nbsp;
            <span>转载规则</span>
        </p>
        
            <div class="center-align">
                <a rel="license noopener" target="_blank" href="https://creativecommons.org/licenses/by/4.0/deed.zh">
                    <img alt=""
                         style="border-width:0"
                         src="https://i.creativecommons.org/l/by/4.0/88x31.png"/>
                </a>
            </div>
            <br/>
            <span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text"
                  property="dct:title" rel="dct:type">
                    《pushdowndb阅读笔记》
                </span> 由
            <a xmlns:cc="http://creativecommons.org/ns#" href="/2021/05/11/pushdowndb-yue-du-bi-ji/" property="cc:attributionName"
               rel="cc:attributionURL">
                JavaGuy
            </a> 采用
            <a rel="license noopener" target="_blank" href="https://creativecommons.org/licenses/by/4.0/deed.zh">
                知识共享署名 4.0 国际许可协议
            </a>进行许可。
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>


        </div>
    </div>

    

    

    

    

    
    <style>
    .valine-card {
        margin: 1.5rem auto;
    }

    .valine-card .card-content {
        padding: 20px 20px 5px 20px;
    }

    #vcomments input[type=text],
    #vcomments input[type=email],
    #vcomments input[type=url],
    #vcomments textarea {
        box-sizing: border-box;
    }

    #vcomments p {
        margin: 2px 2px 10px;
        font-size: 1.05rem;
        line-height: 1.78rem;
    }

    #vcomments blockquote p {
        text-indent: 0.2rem;
    }

    #vcomments a {
        padding: 0 2px;
        color: #42b983;
        font-weight: 500;
        text-decoration: underline;
    }

    #vcomments img {
        max-width: 100%;
        height: auto;
        cursor: pointer;
    }

    #vcomments ol li {
        list-style-type: decimal;
    }

    #vcomments ol,
    ul {
        display: block;
        padding-left: 2em;
        word-spacing: 0.05rem;
    }

    #vcomments ul li,
    ol li {
        display: list-item;
        line-height: 1.8rem;
        font-size: 1rem;
    }

    #vcomments ul li {
        list-style-type: disc;
    }

    #vcomments ul ul li {
        list-style-type: circle;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    #vcomments table, th, td {
        border: 0;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments h1 {
        font-size: 1.85rem;
        font-weight: bold;
        line-height: 2.2rem;
    }

    #vcomments h2 {
        font-size: 1.65rem;
        font-weight: bold;
        line-height: 1.9rem;
    }

    #vcomments h3 {
        font-size: 1.45rem;
        font-weight: bold;
        line-height: 1.7rem;
    }

    #vcomments h4 {
        font-size: 1.25rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    #vcomments h5 {
        font-size: 1.1rem;
        font-weight: bold;
        line-height: 1.4rem;
    }

    #vcomments h6 {
        font-size: 1rem;
        line-height: 1.3rem;
    }

    #vcomments p {
        font-size: 1rem;
        line-height: 1.5rem;
    }

    #vcomments hr {
        margin: 12px 0;
        border: 0;
        border-top: 1px solid #ccc;
    }

    #vcomments blockquote {
        margin: 15px 0;
        border-left: 5px solid #42b983;
        padding: 1rem 0.8rem 0.3rem 0.8rem;
        color: #666;
        background-color: rgba(66, 185, 131, .1);
    }

    #vcomments pre {
        font-family: monospace, monospace;
        padding: 1.2em;
        margin: .5em 0;
        background: #272822;
        overflow: auto;
        border-radius: 0.3em;
        tab-size: 4;
    }

    #vcomments code {
        font-family: monospace, monospace;
        padding: 1px 3px;
        font-size: 0.92rem;
        color: #e96900;
        background-color: #f8f8f8;
        border-radius: 2px;
    }

    #vcomments pre code {
        font-family: monospace, monospace;
        padding: 0;
        color: #e8eaf6;
        background-color: #272822;
    }

    #vcomments pre[class*="language-"] {
        padding: 1.2em;
        margin: .5em 0;
    }

    #vcomments code[class*="language-"],
    pre[class*="language-"] {
        color: #e8eaf6;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }

    #vcomments b,
    strong {
        font-weight: bold;
    }

    #vcomments dfn {
        font-style: italic;
    }

    #vcomments small {
        font-size: 85%;
    }

    #vcomments cite {
        font-style: normal;
    }

    #vcomments mark {
        background-color: #fcf8e3;
        padding: .2em;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }
</style>

<div class="card valine-card" data-aos="fade-up">
    <div id="vcomments" class="card-content"></div>
</div>

<script src="/libs/valine/av-min.js"></script>
<script src="/libs/valine/Valine.min.js"></script>
<!-- <script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script> -->

<script>
    new Valine({
        el: '#vcomments',
        appId: 'GgssQFlBBeYrJoL1y5s8jXeR-gzGzoHsz',
        appKey: 'kXYkbr7xencqP3PxqQNKykdt',
        notify: 'true' === 'true',
        verify: 'false' === 'true',
        visitor: 'true' === 'true',
        avatar: 'wavatar',
        pageSize: '10',
        lang: 'zh-cn',
        placeholder: '如果你没有GitHub账号，还可以在这里评论啦！'
    });
</script>

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fa fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2021/05/12/20210513/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/28.jpg" class="responsive-img" alt="20210513">
                        
                        <span class="card-title">20210513</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            2、PushdownDB论文解读2.1、摘要​        本文研究了下推一部分DBMS分析查询到简单存储服务中的有效性。最近使用的Amazon Web Services（AWS）的（S3）引擎发布了称为S3 Select的功能。 我们展
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="fa fa-clock-o fa-fw icon-date"></i>2021-05-12
                        </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Lab/" class="post-category" target="_blank">
                                    Lab
                                </a>
                            
                            <a href="/categories/Lab/%E5%91%A8%E4%BC%9A%E6%80%BB%E7%BB%93%E6%8A%A5%E5%91%8A/" class="post-category" target="_blank">
                                    周会总结报告
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/PushdownDB/" target="_blank">
                        <span class="chip bg-color">PushdownDB</span>
                    </a>
                    
                    <a href="/tags/S3-Select/" target="_blank">
                        <span class="chip bg-color">S3 Select</span>
                    </a>
                    
                    <a href="/tags/Bloom-filter/" target="_blank">
                        <span class="chip bg-color">Bloom filter</span>
                    </a>
                    
                    <a href="/tags/TOP-K/" target="_blank">
                        <span class="chip bg-color">TOP-K</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fa fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2021/05/05/20210506/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/27.jpg" class="responsive-img" alt="20210506">
                        
                        <span class="card-title">20210506</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            1、王阳阳学长实现部分汇总1.1、查询内并行负载均衡读查找了mPaxos里面所有代码，这一块可以确定没有实现，王阳阳学长改动的部分是在SE 层，这一块需要CE层维护一个任务队列。
1.2、ConcurrentHashMap用来维护分区路由表
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="fa fa-clock-o fa-fw icon-date"></i>2021-05-05
                            </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Lab/" class="post-category" target="_blank">
                                    Lab
                                </a>
                            
                            <a href="/categories/Lab/%E5%91%A8%E4%BC%9A%E6%80%BB%E7%BB%93%E6%8A%A5%E5%91%8A/" class="post-category" target="_blank">
                                    周会总结报告
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E8%AF%BB/" target="_blank">
                        <span class="chip bg-color">负载均衡读</span>
                    </a>
                    
                    <a href="/tags/%E8%99%9A%E6%8B%9F%E5%88%86%E5%8C%BA/" target="_blank">
                        <span class="chip bg-color">虚拟分区</span>
                    </a>
                    
                    <a href="/tags/wyy/" target="_blank">
                        <span class="chip bg-color">wyy</span>
                    </a>
                    
                    <a href="/tags/protobuf/" target="_blank">
                        <span class="chip bg-color">protobuf</span>
                    </a>
                    
                    <a href="/tags/%E5%A4%9A%E7%94%9F%E4%BA%A7%E8%80%85%E5%92%8C%E5%8D%95%E6%B6%88%E8%B4%B9%E8%80%85%E6%A8%A1%E5%9E%8B/" target="_blank">
                        <span class="chip bg-color">多生产者和单消费者模型</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>
</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: JavaGuy的博客<br />'
            + '作者: JavaGuy<br />'
            + '链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () { bodyElement.removeChild(newdiv); }, 200);
    });
</script>

<!-- <script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
<script>
    const btw = new BTWPlugin();
    btw.init({
        id: 'artDetail',
        blogId: '20962-1585405055583-879',
        name: '算法码上来',
        qrcode: 'https://godweiyang.com/medias/gzh.jpg',
        keyword: 'VIP',
    });
</script> -->

    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fa fa-list"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h1, h2, h3, h4, h5, h6'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4, h5, h6').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).slideUp(500);
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).slideDown(500);
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>

<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>
<!-- 代码语言 -->
<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>
<!-- 代码块复制 -->
<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>
<script type="text/javascript" src="/libs/codeBlock/clipboard.min.js"></script>
<!-- 代码块收缩 -->
<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script> 
<!-- 代码块折行 -->
<style type="text/css">code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }</style>


    <footer class="page-footer bg-color">
    <div class="container row center-align">
        <div class="col s12 m8 l8 copy-right">
            &copy; ZhangQu. 版权所有

            
            &nbsp;<i class="fa fa-area-chart"></i>&nbsp;站点总字数:&nbsp;
            <span class="white-color">285.6k</span>
            

            <br>
            <span id="sitetime"></span>

            
            
            <br>
            
            <span id="busuanzi_container_site_pv" style='display:none'>
                <i class="fa fa-heart-o"></i>
                本站总访问量 <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
            <span id="busuanzi_container_site_uv" style='display:none'>
                人次,&nbsp;访客数 <span id="busuanzi_value_site_uv" class="white-color"></span> 人.
            </span>
            
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/zhangqu999" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fa fa-github"></i>
    </a>



    <a href="mailto:zhang1842279380@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fa fa-envelope-open"></i>
    </a>





    <a href="http://wpa.qq.com/msgrd?v=3&uin=1842279380&site=qq&menu=yes" class="tooltipped" target="_blank" data-tooltip="访问我的知乎" data-position="top" data-delay="50">
        <i class="fa fa-qq"></i>
    </a>





    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fa fa-rss"></i>
    </a>
</div>
    </div>
</footer>

<div class="progress-bar"></div>

<!-- 不蒜子计数初始值纠正 -->
<script>
    $(document).ready(function () {

        var int = setInterval(fixCount, 50);
        var pvcountOffset = 1000;
        var uvcountOffset = 200;

        function fixCount() {
            if (document.getElementById("busuanzi_container_site_pv").style.display != "none") {
                $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + pvcountOffset);
                clearInterval(int);
            }
            if ($("#busuanzi_container_site_pv").css("display") != "none") {
                $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + uvcountOffset); // 加上初始数据 
                clearInterval(int);
            }
        }
    });
</script>

<script language=javascript>
    function siteTime() {
        window.setTimeout("siteTime()", 1000);
        var seconds = 1000;
        var minutes = seconds * 60;
        var hours = minutes * 60;
        var days = hours * 24;
        var years = days * 365;
        var today = new Date();
        var todayYear = today.getFullYear();
        var todayMonth = today.getMonth() + 1;
        var todayDate = today.getDate();
        var todayHour = today.getHours();
        var todayMinute = today.getMinutes();
        var todaySecond = today.getSeconds();
        /* Date.UTC() -- 返回date对象距世界标准时间(UTC)1970年1月1日午夜之间的毫秒数(时间戳)
        year - 作为date对象的年份，为4位年份值
        month - 0-11之间的整数，做为date对象的月份
        day - 1-31之间的整数，做为date对象的天数
        hours - 0(午夜24点)-23之间的整数，做为date对象的小时数
        minutes - 0-59之间的整数，做为date对象的分钟数
        seconds - 0-59之间的整数，做为date对象的秒数
        microseconds - 0-999之间的整数，做为date对象的毫秒数 */
        var t1 = Date.UTC(2021, 03, 18, 00, 00, 00); //北京时间2018-2-13 00:00:00
        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
        var diff = t2 - t1;
        var diffYears = Math.floor(diff / years);
        var diffDays = Math.floor((diff / days) - diffYears * 365);
        var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
        var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) / minutes);
        var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours - diffMinutes * minutes) / seconds);
        document.getElementById("sitetime").innerHTML = "本站已运行 " + diffYears + " 年 " + diffDays + " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
    }/*因为建站时间还没有一年，就将之注释掉了。需要的可以取消*/
    siteTime();
</script>

    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fa fa-angle-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <script type="text/javascript"> var OriginTitile = document.title, st; document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ喔哟，崩溃啦！", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) })
    </script>

    <!-- Global site tag (gtag.js) - Google Analytics -->



    
    <script src="/libs/others/clicklove.js"></script>
    

    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    <!-- 雪花特效 -->
    
    <script type="text/javascript" src="/libs/others/snow.js"></script>
    

</body>

</html>